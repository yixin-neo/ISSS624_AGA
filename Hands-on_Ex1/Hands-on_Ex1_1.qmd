---
title: "Hands-on Exercise 1.1: Geospatial Data Wrangling with R"
author: "NeoYX"
date: '14 Nov 2023'
date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  #echo: false
  #message: false
format: 
  html:
    code-fold: false
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

## 1.1 Overview

In this hands-on exercise, I will learn how to import and wrangle geospatial data using appropriate R packages:

-   installing and loading [sf](https://r-spatial.github.io/sf/) and [tidyverse](https://www.tidyverse.org/) packages into R environment,

-   importing geospatial data by using appropriate functions of **sf** package,

-   importing aspatial data by using appropriate function of **readr** package,

-   exploring the content of simple feature data frame by using appropriate **Base R** and **sf** functions,

-   assigning or transforming coordinate systems by using appropriate *sf* functions,

-   converting an aspatial data into a sf data frame by using appropriate function of **sf** package,

-   performing geoprocessing tasks by using appropriate functions of **sf** package,

-   performing data wrangling tasks by using appropriate functions of **dplyr** package and

-   performing Exploratory Data Analysis (EDA) by using appropriate functions from **ggplot2** package.

## 1.2 Data Acquisition

In this hands-on exercise, data is acquired from the following sources:

-   Master Plan 2014 Subzone Boundary (Web) from [data.gov.sg](https://data.gov.sg/)

-   Pre-Schools Location from [data.gov.sg](https://data.gov.sg/)

-   Cycling Path from [LTADataMall](https://www.mytransport.sg/content/mytransport/home/dataMall.html)

-   Latest version of Singapore Airbnb listing data from [Inside Airbnb](http://insideairbnb.com/get-the-data.html)

## 1.3 Getting Started

The code chunk below install and load sf and tidyverse packages into R environment:

```{r}
pacman::p_load(sf, tidyverse)
```

-   **sf** for importing, managing, and processing geospatial data, and

-   **tidyverse** for performing data science tasks such as importing, wrangling and visualising data.

The `sp` package provides classes and methods for spatial data types in 2005. The `sf` package was released in 2016 to give standardise support for vector data in R. It is also coherent with tidyverse, that consists of the following (not exhaustive):

-   **readr** for importing csv data,

-   **readxl** for importing Excel worksheet,

-   **tidyr** for manipulating data,

-   **dplyr** for transforming data, and

-   **ggplot2** for visualising data

## 1.4 Importing Geospatial data

The data that we will be importing takes the following forms:

-   `MP14_SUBZONE_WEB_PL`, a [polygon]{.underline} feature layer in ESRI shapefile format,

-   `CyclingPath`, a [line]{.underline} feature layer in ESRI shapefile format, and

-   `PreSchool`, a [point]{.underline} feature layer in kml file format.

### 1.4.1 Importing polygon feature data in shapefile format

st_read() is a func from `sf` package, used to read files in shapefile format.

dsn- data source name (aka data path)

layer - shapefile name. No extensions like .shp, .dbf, .prj and .shx are needed.

```{r}
mpsz <- st_read(dsn="data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

-   geospatial objects are multipolygon features

-   total of 323 multipolygon features and 15 fields in `mpsz` simple feature data frame.

-   `mpsz` is in **svy21** projected coordinates systems

-   x extend and y extend of the data are given

```{r}
library(knitr)
kable(head(mpsz, n = 3))
```

### 1.4.2 Importing polyline feature data in shapefile form

The code chunk below uses *st_read()* function of **sf** package to import `CyclingPath` shapefile into R as line feature data frame.

```{r}
cyclingpath = st_read(dsn='data/geospatial', layer='CyclingPathGazette')
```

```{r}
kable(head(cyclingpath, n = 3))
```

### 1.4.3 Importing GIS data in kml format

The `pre-schools-location-kml` is in kml format.

```{r}
preschool = st_read('data/geospatial/pre-schools-location-kml.kml')
```

Note that preschool is in WSG84 coordinates system (3D).

```{r}
kable(head(preschool, n = 3))
```

### 1.5.1 Working with *st_geometry()*

The column in the sf data.frame that contains the geometries is a list, of class `sfc`. We can retrieve the geometry list-column in this case by mpsz\$geom or mpsz\[\[1\]\], but the more general way uses *st_geometry()* as shown in the code chunk below.

```{r}
class(mpsz)
```

```{r}
st_geometry(mpsz)
```

### 1.5.2 Working with glimpse()

Beside the basic feature information, we also would like to learn more about the associated **attribute** information in the data frame. This is the time you will find *glimpse()* of **dplyr**. very handy as shown in the code chunk below.

```{r}
glimpse(head(mpsz))
```

*glimpse()* report reveals the data type of each fields. For example `FMEL-UPD_D` field is in **date** data type and `X_ADDR`, `Y_ADDR`, `SHAPE_L` and `SHAPE_AREA` fields are all in **double-precision values**.

### 1.5.3 Working with *head()*

Sometimes we would like to reveal complete information of a feature object, this is the job of [*head()*](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/head) of Base R

```{r}
head(mpsz,3)
```

## 1.6 Plotting the Geospatial Data

In geospatial data science, by looking at the feature information is not enough. We are also interested to **visualise** the geospatial features. One of the ways is to use the *plot()* of R Graphic.

```{r}
plot(mpsz)
```

The default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry (multi-polygon) by using the code chunk below.

```{r}
plot(st_geometry(mpsz))
```

Alternatively, we can also choose the plot the `sf` object by using a specific attribute as shown in the code chunk below.

```{r}
plot(mpsz["REGION_N"])
```

::: {.callout-note appearance="minimal"}
Note: *plot()* is mean for plotting the geospatial object for quick look. For high cartographic quality plot, other R package such as tmap should be used.
:::

## 1.7 Working with Projection

Map projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.

In this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called **projection transformation**.

### 1.7.1 Assigning EPSG code to a simple feature data frame

Common issues:

1.  coordinate system of the source data was missing (such as due to missing .proj for ESRI shapefile)

2.  wrongly assigned during the importing process

Using the st_crs() to check in detail of the `mpsz`reveals that although it claims to be in svy21 (singapore proj sys), reading until end of print shows that it is wrongly in EPSG9001 (singapore uses epsg3414)

```{r}
st_crs(mpsz)
```

In order to assign the correct EPSG code to `mpsz` data frame, *st_set_crs()* of **sf** package is used as shown in the code chunk below.

```{r}
mpsz3414 <- st_transform(mpsz, 3414)
```

Recheck

```{r}
st_crs(mpsz3414)
```

Notice that the EPSG code is 3414 now.

### 1.7.2 Transforming the projection of preschool from wgs84 to svy21 (EPSG3414).

In geospatial analytics, it is very common for us to transform the original data from **geographic** coordinate system (3D) to **projected** coordinate system (2D). This is because geographic coordinate system is not appropriate if the analysis need to use **distance** or/and **area** measurements.

Let us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system (3D).

```{r}
st_geometry(preschool)
```

```{r}
st_crs(preschool)
```

Note that *`st_set_crs()`* is not appropriate and *`st_transform()`* of sf package should be used. This is because we need to reproject `preschool` from one coordinate system to another coordinate system **mathemetically**.

Let us perform the projection transformation by using the code chunk below.

```{r}
preschool3414 <- st_transform(preschool, crs=3414)
```

Recheck

```{r}
#| echo: false
st_geometry(preschool3414)
```

Notice that it is in svy21 projected coordinate system now. Furthermore, if we refer to *Bounding box:*, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.

## 1.8 Importing and Converting An Aspatial Data

In practice, it is not unusual that we will come across data such as `listing` of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- (**long**) and y-coordinates (**lat**) of the data points.

In this section, we will learn how to

1.  import an aspatial data into R environment and save it as a tibble data frame

2.  convert it into a simple feature data frame.

The `listings.csv` data downloaded from AirBnb will be used.

### 1.8.1 Importing the aspatial data

Since `listings` data set is in csv file format, we will use [*read_csv()*](https://readr.tidyverse.org/reference/read_delim.html) of **readr** package to import `listing.csv` as shown the code chunk below. The output R object is called `listings` and it is a [tibble data frame](https://r4ds.had.co.nz/tibbles.html).

```{r}
listings <- read_csv('data/aspatial/listings.csv')
class(listings)
```

After importing the data file into R, it is important for us to examine if the data file has been imported correctly.

The code chunk below shows *list()* of Base R instead of *glimpse()* is used to do the job.

```{r}
list(listings)
```

Other ways of displaying tabular data in R:

::: panel-tabset
## kable

```{r}
kable(head(listings))
```

## gt

```{r}
library(gt)
head(listings) %>% gt() %>% tab_header(title = "AirBnB listings")
```

## DT (interactive table)

```{r}
#| eval: false
library(DT)
datatable(head(listings), class = 'cell-border stripe', options = list(pageLength = 3))
```
:::

Two useful fields we need are `latitude` and `longitude` and they are in decimal degree format. As a best guess, we will assume that the data is in **wgs84** Geographic Coordinate System.

### 1.8.2 Creating a simple feature data frame from an aspatial data frame

The code chunk below converts `listing` data frame into a simple feature data frame by using [*st_as_sf()*](https://r-spatial.github.io/sf/reference/st_as_sf.html) of **sf** packages.

EPSG 4326 is associated with WGS84.

```{r}
listings_sf <- st_as_sf(listings,
                        coords = c('longitude','latitude'),
                        crs=4326) %>%
  st_transform(crs=3414)

class(listings_sf)
```

Things to learn from the arguments above:

-   *coords* argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.

-   *crs* argument requires you to provide the coordinates system in epsg format. [EPSG: 4326](https://epsg.io/4326) is wgs84 Geographic Coordinate System and [EPSG: 3414](https://epsg.io/3414) is Singapore SVY21 Projected Coordinate System. You can search for other country's epsg code by referring to [epsg.io](https://epsg.io/).

Let us examine the content of our newly created sf dataframe

```{r}
glimpse(listings_sf)
```

A new column `geometry` has been added at the back of the df. Additionally, lat long columns were both dropped from the df.

## 1.9 Geoprocessing with sf package

Besides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, **sf** package also offers a wide range of geoprocessing (also known as GIS analysis) functions.

In this section, we will learn how to perform two commonly used geoprocessing functions, namely [buffering](https://www.gislounge.com/buffers-in-gis/) and point in polygon count.

### 1.9.1 Buffering

**The scenario:**

The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.

**The solution:**

A buffer is a zone around a spatial object, recall that `cyclingpath` is a multiline-string sf object.

```{r}
st_geometry(cyclingpath)
```

Firstly, `st_buffer()` of sf package is used to compute the 5-meter buffers around cyclingpath .

```{r}
#| code-fold: false
buffer_cycling <- st_buffer(cyclingpath,
                            dist = 5,
                            nQuadSegs = 30)
```

Take a peak at this df before calculating area.

```{r}
head(buffer_cycling)
```

Now, we will calculate the area of the buffers as shown in the code chunk below.

We are also adding a derived column to `buffer_cycling` too.

```{r}
#| code-fold: false
buffer_cycling$AREA <- st_area(buffer_cycling)
kable(head(buffer_cycling))
```

Lastly, sum() of Base R will be used to derive the total land involved

```{r}
sum(buffer_cycling$AREA)
```

**Good Job!**

**Mission Accomplished!**

### 1.9.2 Point-in-polygon count

**The scenario:**

A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.

Before that, lets double confirm both data are using same projection system.

```{r}
identical(st_crs(mpsz3414), st_crs(preschool3414))
```

**The solution:**

The code chunk below performs two operations at one go.

1.  identify pre-schools located inside each Planning Subzone by using [st_intersects()](https://r-spatial.github.io/sf/reference/geos_binary_pred.html).

2.  length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.

```{r}
mpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414,preschool3414))
```

::: {.callout-warning appearance="minimal"}
st_intersects(): count points in polygon

st_intersection(): find polygon areas overlap
:::

Now check summary stats of `PreSch Count` column in each subzone.

```{r}
summary(mpsz3414$`PreSch Count`)
```

To list the planning subzone with the most number of pre-school, the [*top_n()*](https://dplyr.tidyverse.org/reference/top_n.html) of **dplyr** package can be used.

```{r}
kable(top_n(mpsz3414, 3, `PreSch Count`) %>%
        arrange(desc(`PreSch Count`)))
```

To calculate the density (# schools/subzone area) of preschool by planning subzone :

```{r}
mpsz3414 <- mpsz3414 %>%
  mutate(AREA = st_area(mpsz3414),
         DENSITY = `PreSch Count` /AREA * 1000000) %>% 
  arrange(desc(DENSITY))

kable(head(mpsz3414))
```

The table above shows the top 6 highest density subzones .

```{r}
#| code-fold: True
#| eval: false
#| echo: false
```

## 1.10 Explorotary Data Analysis (EDA)

In practice, many geospatial analytics start with Exploratory Data Analysis. In this section, wewill learn how to use appropriate [ggplot2](https://ggplot2.tidyverse.org/) functions to create functional and yet truthful statistical graphs for EDA purposes.

Firstly, we will plot a histogram to reveal the distribution of `PreSch Density`. Conventionally, *hist()* of R Graphics will be used as shown in the code chunk below.

```{r}
hist(mpsz3414$DENSITY)
```

Although the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.

In the code chunk below, appropriate **ggplot2** functions will be used.

::: panel-tabset
## Static

```{r}
q <- quantile(as.numeric(mpsz3414$DENSITY), probs = c(0.25, 0.5, 0.75))

ggplot(data=mpsz3414, 
       aes(x= as.numeric(DENSITY)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  geom_vline(xintercept = q[2]+1, linetype='dashed', size = 0.5, color='blue') +
  geom_vline(xintercept = q[3]+1, linetype='dashed', size = 0.5) +
  annotate('text' , x= 4, y=75, label='50th \npercentile', size = 2) +
  annotate('text' , x= 9, y=75, label='75th \npercentile', size = 2) +
  labs(title = "Are pre-school even distributed in Singapore?",
       subtitle= "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",
      x = "Pre-school density (per km sq)",
      y = "Frequency")
```

## Interactive (plotly)

```{r}
library(plotly)
q <- quantile(as.numeric(mpsz3414$DENSITY), probs = c(0.25, 0.5, 0.75))

p <- ggplot(data=mpsz3414, 
       aes(x= as.numeric(DENSITY)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  geom_vline(xintercept = q[2]+1, linetype='dashed', size = 0.5, color='blue') +
  geom_vline(xintercept = q[3]+1, linetype='dashed', size = 0.5) +
  annotate('text' , x= 4, y=75, label='50th \npercentile', size = 2) +
  annotate('text' , x= 9, y=75, label='75th \npercentile', size = 2) +
  labs(title = "Are pre-school even distributed in Singapore?",
       subtitle= "There are many planning sub-zones with a single pre-school, on the other hand, \nthere are two planning sub-zones with at least 20 pre-schools",
      x = "Pre-school density (per km sq)",
      y = "Frequency")

ggplotly(p)
```
:::

**DIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.**

```{r}
ggplot(data=mpsz3414, 
       aes(y = `PreSch Count`, 
           x= as.numeric(DENSITY)))+
  geom_point(color="black", 
             fill="light blue") +
  xlim(0, 40) +
  ylim(0, 40) +
  labs(title = "",
      x = "Pre-school density (per km sq)",
      y = "Pre-school count")
```

## Theories

### KML and shapefiles

A KMZ file is a zipped (or compressed) KML file, and a SHZ is a zipped/compressed Shapefile.

A shapefile is an Esri vector data storage format for storing the location, shape, and attributes of geographic features. It is stored as a set of related files and contains one feature class.

The shapefile format can spatially describe vector features: **points, lines, and polygons**, representing, for example, water wells, rivers, and lakes. Each item usually has attributes that describe it, such as name or temperature.

KML and Shapefiles could contain the exact same data, however KML (Keyhole Markup Language) is much more suited to displaying time based track information, whereas shapefiles are more suited to displaying Geometries, like boundaries, areas, roads, etc.

**Shapefiles are composed of 3 mandatory files**

·       . shp (geometry), \<- multipolygon, polylines or points. Can only be one type in each file , can combined in layers

·       . dbf (attributes) \<- table

·       . shx (index)  \<- binds first two together

### GCS \[Geographic Coordinate System\] (3D) and PCS \[Projected Coordinate System \] (2D)

**GCS**: uses lat, long, elevation to locate positions on Earth. Units are in degree and metres. Earth is represented as a [sphere]{.underline}. Eg. WGS84 (world Gedetic system 1984)

**PCS**: Units are usually metres to locate position on a [Flat]{.underline} surface. Involves projecting 3D Earth into a 2D plane. It distorts the true [shapes]{.underline}, [areas]{.underline}, [distances]{.underline}, or [directions]{.underline} to some extent, depending on the projection method chosen.

Preserve:

·       Conformal projections minimize distortion in **shape**

·       Equidistant projections minimize distortion in **distance**

·       Equal-area projection minimize distortion in **area**

·       Azimuthal or True-direction projections minimize distortion in **direction**.

Google maps uses Mercator projection system. It is chosen as it preserves direction and angles. It is useful for navigation (google map) . It is originally created for sea navigation in older days. The cons are that this projection does not preserve area and shape.

Singapore uses **SVY21** or the **EPSG:3414** projected coordinate system.

### Geospatial data handling functions

-   st_read & read sf: read simple features from file or database, or retrieve layer names and their geometry type(s)

-   st write &write_sf: write simple features object to file or database

-   st_as_sf: convert a sf object from a non-geospatial tabular data frame

-   st as_text: convert to Well Known Text(WKT)

-   st as_binary: convert to Well Known Binary(WKB)

-   st_as_sfc: convert geometries to sfc (e.g., from WKT, WKB) as(x, "Spatial"): convert to Spatial\*

-   st transform(x, crs, ...): convert coordinates of x to a different coordinate reference system

The code chunk below allows us to unsf the mpsz and work tbl_df or data.frame.

```{r}
#| eval: false
mpsz_tbl_df <- as_tibble(mpsz)
```
