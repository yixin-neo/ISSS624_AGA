{
  "hash": "e3a1462305178afb403c150129a17482",
  "result": {
    "markdown": "---\ntitle: \"Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation\"\nauthor: \"NeoYX\"\ndate: '22 Nov 2023'\ndate-modified: \"2023-11-22\"\neditor: visual\nexecute: \n  freeze: auto\n  warning: false\n  #echo: false\n  #message: false\nformat: \n  html:\n    code-fold: False\n    code-overflow: scroll\n    code-summary: \"Show the code\"\n    code-line-numbers: true\n---\n\n\n## **10.1 Overview**\n\nIn this hands-on exercise, wewill learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using **spdep** package. By the end to this hands-on exercise, we will be able to:\n\n-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep** package,\n\n    -   plot Moran scatterplot,\n\n    -   compute and plot spatial correlogram using appropriate function of **spdep** package.\n\n-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package;\n\n-   compute Getis-Ord\\'s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of **spdep** package; and\n\n-   to visualise the analysis output by using **tmap** package.\n\n## **10.2 Getting Started**\n\n### **10.2.1 The analytical question**\n\n-   In spatial policy, local government/planners aims to ensure equal distribution of development in the province.\n\n-   we should apply appropriate spatial statistical methods to discover if development are even distributed geographically in the province\n\n-   if answer is NO, we ask \\\"is there sign of clustering?\\\" (GLOBAL spatial autocorrelation)\n\n-   if YES, \\\"Where are the clusters\\\" (LOCAL spatial autocorrelation)\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China. (https://en.wikipedia.org/wiki/Hunan)\n\n### **10.2.2 The Study Area and Data**\n\nTwo data sets will be used in this hands-on exercise, they are:\n\n1.  Geospatial data: Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\n\n2.  Aspatial data: Hunan_2012.csv: This csv file contains selected Hunan\\'s local development indicators in 2012.\n\n### **10.2.3 Setting the Analytical Toolls**\n\nPackages that we will be using are:\n\n-   sf is use for importing and handling geospatial data in R,\n\n-   tidyverse is mainly use for wrangling attribute data in R,\n\n-   spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\n\n-   tmap will be used to prepare cartographic quality chropleth map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n```\n:::\n\n\n## \n**10.3 Getting the Data Into R Environment**\n\nThe geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n### **10.3.1 Import shapefile into r environment**\n\nThe code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.\n\n`hunan` is in WSG84 geographical system.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn='data/geospatial',\n                 layer='Hunan')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `Hunan' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\n### **10.3.2 Import csv file into r environment**\n\nNext, we will import *Hunan_2012.csv* into R by using *read_csv()* of **readr** package. The output is R data frame class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv('data/aspatial/Hunan_2012.csv')\nhead(hunan2012,3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 29\n  County  City  avg_wage deposite   FAI Gov_Rev Gov_Exp    GDP GDPPC   GIO  Loan\n  <chr>   <chr>    <dbl>    <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 Anhua   Yiya…    30544   10967  6832.    457.   2703  13225  14567 9277. 3955.\n2 Anren   Chen…    28058    4599. 6386.    221.   1455.  4941. 12761 4189. 2555.\n3 Anxiang Chan…    31935    5517. 3541     244.   1780. 12482  23667 5109. 2807.\n# ℹ 18 more variables: NIPCR <dbl>, Bed <dbl>, Emp <dbl>, EmpR <dbl>,\n#   EmpRT <dbl>, Pri_Stu <dbl>, Sec_Stu <dbl>, Household <dbl>,\n#   Household_R <dbl>, NOIP <dbl>, Pop_R <dbl>, RSCG <dbl>, Pop_T <dbl>,\n#   Agri <dbl>, Service <dbl>, Disp_Inc <dbl>, RORP <dbl>, ROREmp <dbl>\n```\n:::\n:::\n\n\n### **10.3.3 Performing relational join**\n\nThe code chunk below will be used to update the attribute table of *hunan*\\'s SpatialPolygonsDataFrame (geospatial) with the attribute fields of *hunan2012* dataframe (aspatial) . This is performed by using *left_join()* of **dplyr** package. Since the join columns are not specified, identical columns names (\\'County\\') form both dataset will be used for the join.\n\nColumn 7 and 15 are the \\'County\\' and \\'GDPPC\\' columns respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n```\n:::\n\n\n### **10.3.4 Visualising Regional Development Indicator**\n\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using *qtm()* of **tmap** package.\n\n-   tm_fill() \\'s **n** refer to the number of equal intervals\n\n\n::: {.cell}\n\n```{.r .cell-code}\nequal <- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n=5,\n          style='equal') +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = 'Equal interval classification',\n            main.title.size=1.5,\n            legend.height = 0.25,\n            legend.width = 0.25)\n\nquantile <- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n=5,\n          style='quantile') +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = 'Equal quantile classification',\n            main.title.size=1.5,\n            legend.height = 0.25,\n            legend.width = 0.25)\n\ntmap_arrange(equal, quantile, asp =1, ncol=2)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex2_3_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell fig.asp='0.68'}\n\n:::\n\n\n## Theories\n\n### \n",
    "supporting": [
      "Hands-on_Ex2_3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}