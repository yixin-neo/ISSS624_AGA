---
title: "Take-home_Ex1: Geospatial Analytics for Public Good "
author: "NeoYX"
date: '24 Nov 2023'
date-modified: "`r Sys.Date()`"
editor: visual
execute: 
  freeze: auto
  warning: false
  #echo: false
  #message: false
format: 
  html:
    code-fold: False
    code-overflow: scroll
    code-summary: "Show the code"
    code-line-numbers: true
---

## **Setting the Scene**

The increasing digitization of urban infrastructures, such as public transportation and utilities, generates vast datasets using technologies like GPS and RFID. These datasets offer valuable insights into human movement patterns within a city, especially with the widespread deployment of smart cards and GPS devices in vehicles. However, current practices often limit the use of this data to basic tracking and mapping with GIS applications, primarily because conventional GIS lacks advanced functions for analyzing and modeling spatial and spatio-temporal data effectively. Enhanced analysis of these datasets could significantly contribute to better urban management and informed decision-making for both public and private urban transport services providers.

## **Objectives of Take-home_Ex1**

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, we are tasked to apply appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

## **The Data**

### **Aspatial data**

For this take-home exercise, *Passenger Volume by Origin Destination Bus Stops* downloaded from [LTA DataMall](https://www.waterpointdata.org/access-data/) will be used. It contains the number of trips by [weekdays]{.underline} and [weekends]{.underline} from origin to destination bus stops.

For this exercise, the data is collected in August 2023. The fields are YEAR_MONTH, DAY_TYPE, TIME_PER_HOUR, PT_TYPE , ORIGIN_PT_CODE, DESTINATION_PT_CODE, TOTAL_TRIPS . A sample row for bus dataset could be '2023-08, WEEKDAY, 16, BUS, 28299, 28009, 63'. TIME_PER_HOUR of 16 represents data is collected between 4 pm to 5pm.

### **Geospatial data**

Two geospatial data will be used in this study, they are:

-   *Bus Stop Location* from LTA DataMall's static dataset. It provides information about all the bus stops currently being serviced by buses, including the bus stop code (identifier) and location coordinates.

-   *hexagon*, a [hexagon](https://desktop.arcgis.com/en/arcmap/latest/tools/spatial-statistics-toolbox/h-whyhexagons.htm) layer of 250m (this distance is the perpendicular distance between the centre of the hexagon and its edges.) should be used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.

## **The Task**

The specific tasks of this take-home exercise are as follows:

### **Geovisualisation and Analysis**

-   With reference to the time intervals provided in the table below, compute the passenger trips generated by origin at the hexagon level,

    | Peak hour period             | Bus tap on time |
    |------------------------------|-----------------|
    | Weekday morning peak         | 6am to 9am      |
    | Weekday afternoon peak       | 5pm to 8pm      |
    | Weekend/holiday morning peak | 11am to 2pm     |
    | Weekend/holiday evening peak | 4pm to 7pm      |

-   Display the geographical distribution of the passenger trips by using appropriate geovisualisation methods,

-   Describe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).

### **Local Indicators of Spatial Association (LISA) Analysis**

-   Compute LISA of the passengers trips generate by origin at hexagon level.

-   Display the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value \< 0.05)

-   With reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).

### **Emerging Hot Spot Analysis(EHSA)**

With reference to the passenger trips by origin at the hexagon level for the four time intervals given above:

-   Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values,

-   Prepared EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value \< 0.05).

-   With reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).

## Getting Started

```{r}
pacman::p_load(sf, tmap, tidyverse, knitr, h3jsr, DT, skimr, ggplot2)
```

## Importing Data

### Aspatial data

Import the *Passenger volume by Origin Destination Bus Stops* dataset downloaded from the LTA Datamall by using the read_csv() of the **readr** package.

```{r}
odbus_aug <- read_csv("data/aspatial/origin_destination_bus_202308.csv")
```

Check the datafields

```{r}
glimpse(odbus_aug)
```

#### Processing the aspatial OD data

The '*ORIGIN_PT_CODE*' and '*DESTINATION_PT_CODE*' field is in character field. We will convert it to factor data type.

```{r}
odbus_aug$ORIGIN_PT_CODE <- as.factor(odbus_aug$ORIGIN_PT_CODE)
odbus_aug$DESTINATION_PT_CODE <- as.factor(odbus_aug$DESTINATION_PT_CODE)
```

The function below will extract origin data based on the four time intervals required by the task. The expected arguments are

1.  daytype: 'WEEKDAY' or 'WEEKENDS/HOLIDAY'
2.  timeinterval: c(8,10) if we want data from 8am to 11am.

The function will also compute the sum of all trips by 'ORIGIN_PT_CODE' for each time interval and stored under a new field called 'TRIPS'.

```{r}
get_origin <- function(daytype, timeinterval) {
  result <- odbus_aug %>%
    filter(DAY_TYPE == daytype) %>%
    filter(TIME_PER_HOUR >= timeinterval[1] & TIME_PER_HOUR <= timeinterval[2]) %>%
    group_by(ORIGIN_PT_CODE) %>%
    summarise(TRIPS = sum(TOTAL_TRIPS))
  
  return(result)
}
```

Let's get the data using *get_origin* function

```{r}
origin_day_am <- get_origin('WEEKDAY', c(6, 8))
origin_day_pm <- get_origin('WEEKDAY', c(5, 7))


origin_end_am <- get_origin('WEEKENDS/HOLIDAY', c(11, 13))
origin_end_pm <- get_origin('WEEKENDS/HOLIDAY', c(4, 6))

```

Take a look at overview of all the four dataframes.

::: panel-tabset
#### WD morning peak

```{r}
glimpse(origin_day_am)
```

#### WD afternoon peak

```{r}
glimpse(origin_day_pm)
```

#### WE morning peak

```{r}
glimpse(origin_end_am)
```

#### WE afternoon peak

```{r}
glimpse(origin_end_pm)
```
:::

### Geospatial data

The code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import hexagon shapefile into R. The output will be a **sf polygon** object with 3125 polygons and 6 fields. There also 3125 unique values of the '*fid*' and '*id*' fields and 'fid' can be considered unique identifiers of the hexagons.

```{r}
hex <- st_read(dsn="data/geospatial/hexagon", layer = "hexagon") %>% 
  st_transform(crs = 3414)

hex
```

Take a look at the spatial units:

```{r}
plot(hex['id'])
```

Next, we will import the Bus Stop Location shapefiles into R. The output will be a **sf point** object with 5161 points and 3 fields. As the raw data is in WSG84 geographical coordinate system, we will convert it to EPSG 3414, the projected coordinate system for Singapore.

```{r}
busstop <- st_read(dsn="data/geospatial/BusStopLocation/BusStopLocation_Jul2023", layer = "BusStop") %>% 
  st_transform(crs = 3414)

busstop
```

Checking for duplicates in the 'BUS_STOP_N' field reveals that there are about 16 repeated bus stop numbers. However, they have different geometry in the simple feature `busstop` object above. These could be due to temprorary bus stops . We should retain all these rows as they might have different hexagon '*fid*' values later.

```{r}
busstop %>% 
  st_drop_geometry() %>% 
  group_by(BUS_STOP_N) %>%
  filter(n()>1) %>%
  ungroup() %>% 
  arrange(BUS_STOP_N)
```

Take for instance bus stop number 51071 with two different geometry values.

```{r}
busstop[3470,]
```

```{r}
busstop[3472,]
```

#### Geospatial data wrangling

##### Combining `busstop` and `hex`

The code chunk below performs points and hexagon polygon overlap and the output will be in **sf point** object.

[Before overlapping:]{.underline}

`busstop` : 5161 points

`hex` : 3125 hexagons

[After overlapping:]{.underline}

`busstop_hex` : 5109 points. The reason for this reduction could be due to some points falling out of the boundary of the Singapore boundary in `hex`.

```{r}
busstop_hex <- st_intersection(busstop, hex) %>% 
  select(BUS_STOP_N, fid, id, left, top, right, bottom)

busstop_hex
```

We will drop the geometry because `busstop_hex` is a POINT sf object, there is no hex polygon geometry data for us to plot based on hexagon level. Furthermore, we have to process the attribute data. To get back the hexagon POLYGON geometry data, we can always left_join() hex df with our processed df again later. We will then use `datatable()` function of the [DT](https://rstudio.github.io/DT/) library to print the data.

```{r}
busstop_hex <- busstop_hex  %>% 
  st_drop_geometry()

datatable(busstop_hex, class = 'cell-border stripe', options = list(pageLength = 5))
```

Let us check for duplicates in `busstop_hex` df as it will be used to perform a left join later. The output shows that there are 10 duplicated rows.

```{r}
busstop_hex %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

Removal of duplicates

```{r}
busstop_hex <- unique(busstop_hex)
```

Check again to be sure. All's good.

```{r}
busstop_hex[duplicated(busstop_hex), ]
```

##### Combining each of the four aspatial dataframes with `busstop_hex`

The function below performs left outer join for each of the four aspatial origin dataframes with `busstop_hex` geospatial dataframe. The expected argument is

asp_df: name of aspatial origin dataframe like *origin_day_am* or *origin_day_pm* etc..

The function will also rename '*ORIGIN_PT_CODE*' and '*fid*' fields to '*ORIGIN_BS*' and '*ORIGIN_HEXFID*' respectively.

```{r}
leftjoin <- function(asp_df) {
  result <- left_join(asp_df, busstop_hex,
                         by = c('ORIGIN_PT_CODE' = 'BUS_STOP_N')) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_HEXFID = fid) %>% 
  select(ORIGIN_HEXFID, 
         ORIGIN_BS, 
         TRIPS)
  
  return(result)
}
```

Use the leftjoin function to get our dataframes containing hexagon fids and origin bus stop ids.

The number of rows increased after left join , this could be due to duplicates in the `BUS_STOP_N` field (but different geometry coordinates) that originated from `busstop` and `busstop_hex` dataframes earlier.

```{r}
origin_data_day_am <- leftjoin(origin_day_am)
origin_data_day_pm <- leftjoin(origin_day_pm)
origin_data_end_am <- leftjoin(origin_end_am)
origin_data_end_pm <- leftjoin(origin_end_pm)
```

Again, double check for duplicates

```{r}
origin_data_day_am[duplicated(origin_data_day_am), ]
origin_data_day_pm[duplicated(origin_data_day_pm), ]
origin_data_end_am[duplicated(origin_data_end_am), ]
origin_data_end_pm[duplicated(origin_data_end_pm), ]
```

FYI: Which bus stop numbers are repeated?

```{r}
busstop_hex['BUS_STOP_N'][duplicated(busstop_hex['BUS_STOP_N']), ]
```

Since we are plotting the number of passenger trips generated by hexagon level, we should aggregate the total trips by '*ORIGIN_HEXFID*' and store these values in a new field called '*TTRIPS*'.

```{r}
get_ttrips <- function(df) {
  result<- df %>% 
    group_by(ORIGIN_HEXFID) %>% 
    summarise(TTRIPS = sum(TRIPS)) %>% 
    ungroup()
  return(result) 
}

origin_data_day_am_hex <- get_ttrips(origin_data_day_am) # 5011 to 1453 rows
origin_data_day_pm_hex <- get_ttrips(origin_data_day_pm) # 4971 to 1448 rows
origin_data_end_am_hex <- get_ttrips(origin_data_end_am) # 5000 to 1463 rows
origin_data_end_pm_hex <- get_ttrips(origin_data_end_pm) # 4628 to 1412 rows
```

Print out the above four dataframes

::: panel-tabset
##### origin_data_day_am

```{r}
datatable(origin_data_day_am_hex, class = 'cell-border stripe', options = list(pageLength = 5))
```

##### origin_data_day_pm

```{r}
datatable(origin_data_end_am_hex, class = 'cell-border stripe', options = list(pageLength = 5))
```

##### origin_data_end_am

```{r}
datatable(origin_data_day_am_hex, class = 'cell-border stripe', options = list(pageLength = 5))
```

##### origin_data_end_pm

```{r}
datatable(origin_data_day_pm_hex, class = 'cell-border stripe', options = list(pageLength = 5))
```
:::

##### Retrieve hexagon geometry coordinates 

In order to plot choropleth maps, we need the geometry data from `hex` sf object.

The code below

```{r}
get_hexgeo <- function(df) {
  result <- left_join(hex,df,
                      by = c('fid' = 'ORIGIN_HEXFID'))
  return(result)
}

day_am <- get_hexgeo(origin_data_day_am_hex)
day_pm <- get_hexgeo(origin_data_day_pm_hex)
end_am <- get_hexgeo(origin_data_end_am_hex)
end_pm <- get_hexgeo(origin_data_end_pm_hex)
```

### Choropleth maps 

In this section , the choropleth maps will show the geographical distribution of the passenger trips by origin.

Combine all the dfs and generate plots to check distribution of 'TTRIPS'.

```{r}
origin_data_day_am_hex$source <- 'Wkday_am'
origin_data_day_pm_hex$source <- 'Wkday_pm'
origin_data_end_am_hex$source <- 'Wkend_am'
origin_data_end_pm_hex$source <- 'Wkend_pm'

combine <- rbind(origin_data_day_am_hex,
                 origin_data_day_pm_hex,
                 origin_data_end_am_hex,
                 origin_data_end_pm_hex)
```

```{r}
#| eval: false
#| echo: false
library(gt)
library(rstatix)
qq <- ggplot(combine,
             aes(sample=TTRIPS)) + 
  
  stat_qq() +
  stat_qq_line() +
  ggtitle("QQ plot with Shapiro-Wilk test results")  

qq
```

Plot boxplots to get a general sensing of 'TTRIPS' across different time intervals.

```{r}
ggplot(data=combine, 
       aes(y=TTRIPS,
           x=source)) +
  geom_boxplot() +
  geom_point(stat="summary",        
             fun.y="mean",           
             colour ="red",          
             size=2)
```

Check summary statistics of `TTRIPS` before setting customed break points.

```{r}
summary(combine$TTRIPS)
```

To calculate the outlier values

```{r}
Q1 <- summary(combine$TTRIPS)[2]
Q3 <- summary(combine$TTRIPS)[5]
IQR_value <- Q3 - Q1

lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value

lower_bound
upper_bound
```

With reference to summary statistics and upper bound values,

-   Min : 1 , Max : 447,968

-   break points can be 250, 1500, 7600, 18650

-   break vector is thus c(0, 250 1500, 7600, 18650, 447968)

```{r}
plotmap <- function(df, title) {
  result <- tm_shape(df)+
  tm_fill("TTRIPS", 
          breaks = c(0, 250, 1500, 7600, 18650, 60000, 100000, 447968),
          #style = "quantile", 
          palette = "Blues",
          #legend.hist = TRUE, 
          #legend.is.portrait = TRUE,
          #legend.hist.z = 0.3,
          title = "Passengers Trip") +
  tm_layout(main.title = title,
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            #legend.outside = TRUE,
            #legend.text.size= 0.6,
            #inner.margins = c(0.01, 0.01, 0, .15),
            #legend.position = c("right", "top"),
            #bg.color = "black",
            #main.title.color = 'white',
            #legend.title.color = 'white',
            #legend.text.color= 'white',
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2) +
  tm_credits("Source: Passenger Bus origin and destination data and Bus Stop Location data from LTA datamall", 
             position = c("left", "bottom"))
  return(result)
}
```

```{r}
p1 <- plotmap(day_am, 'Weekday-Morning-Peak Passenger Trips by Origin')
p2 <- plotmap(day_pm, 'Weekday-Afternoon-Peak Passenger Trips by Origin')
p3 <- plotmap(end_am, 'Weekend-Morning-Peak Passenger Trips by Origin')
p4 <- plotmap(end_am, 'Weekend-Afternoon-Peak Passenger Trips by Origin')
```

```{r}
#| fig-width: 14
#| fig-asp: 0.68
p1
```

```{r}
#| fig-width: 14
#| fig-asp: 0.68
p2
```

```{r}
#| fig-width: 14
#| fig-asp: 0.68
p3
```

```{r}
#| fig-width: 14
#| fig-asp: 0.68
p4
```

Describe the spatial patterns revealed by the geovisualisation

```{r}
#| eval: false
#| echo: false
#| code-fold: True
#| fig-width: 14
#| fig-asp: 0.68
```

### 
