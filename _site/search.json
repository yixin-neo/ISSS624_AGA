[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I will learn how to import and wrangle geospatial data using appropriate R packages:\n\ninstalling and loading sf and tidyverse packages into R environment,\nimporting geospatial data by using appropriate functions of sf package,\nimporting aspatial data by using appropriate function of readr package,\nexploring the content of simple feature data frame by using appropriate Base R and sf functions,\nassigning or transforming coordinate systems by using appropriate sf functions,\nconverting an aspatial data into a sf data frame by using appropriate function of sf package,\nperforming geoprocessing tasks by using appropriate functions of sf package,\nperforming data wrangling tasks by using appropriate functions of dplyr package and\nperforming Exploratory Data Analysis (EDA) by using appropriate functions from ggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#data-acquisition",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#data-acquisition",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nIn this hands-on exercise, data is acquired from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#getting-started",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nThe code chunk below install and load sf and tidyverse packages into R environment:\n\npacman::p_load(sf, tidyverse)\n\n\nsf for importing, managing, and processing geospatial data, and\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nThe sp package provides classes and methods for spatial data types in 2005. The sf package was released in 2016 to give standardise support for vector data in R. It is also coherent with tidyverse, that consists of the following (not exhaustive):\n\nreadr for importing csv data,\nreadxl for importing Excel worksheet,\ntidyr for manipulating data,\ndplyr for transforming data, and\nggplot2 for visualising data"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.4 Importing Geospatial data",
    "text": "1.4 Importing Geospatial data\nThe data that we will be importing takes the following forms:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Importing polygon feature data in shapefile format\nst_read() is a func from sf package, used to read files in shapefile format.\ndsn- data source name (aka data path)\nlayer - shapefile name. No extensions like .shp, .dbf, .prj and .shx are needed.\n\nmpsz <- st_read(dsn=\"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ngeospatial objects are multipolygon features\ntotal of 323 multipolygon features and 15 fields in mpsz simple feature data frame.\nmpsz is in svy21 projected coordinates systems\nx extend and y extend of the data are given\n\n\nlibrary(knitr)\nkable(head(mpsz, n = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nSUBZONE_NO\nSUBZONE_N\nSUBZONE_C\nCA_IND\nPLN_AREA_N\nPLN_AREA_C\nREGION_N\nREGION_C\nINC_CRC\nFMEL_UPD_D\nX_ADDR\nY_ADDR\nSHAPE_Leng\nSHAPE_Area\ngeometry\n\n\n\n\n1\n1\nMARINA SOUTH\nMSSZ01\nY\nMARINA SOUTH\nMS\nCENTRAL REGION\nCR\n5ED7EB253F99252E\n2014-12-05\n31595.84\n29220.19\n5267.381\n1630379.3\nMULTIPOLYGON (((31495.56 30…\n\n\n2\n1\nPEARL’S HILL\nOTSZ01\nY\nOUTRAM\nOT\nCENTRAL REGION\nCR\n8C7149B9EB32EEFC\n2014-12-05\n28679.06\n29782.05\n3506.107\n559816.2\nMULTIPOLYGON (((29092.28 30…\n\n\n3\n3\nBOAT QUAY\nSRSZ03\nY\nSINGAPORE RIVER\nSR\nCENTRAL REGION\nCR\nC35FEFF02B13E0E5\n2014-12-05\n29654.96\n29974.66\n1740.926\n160807.5\nMULTIPOLYGON (((29932.33 29…\n\n\n\n\n\n\n\n1.4.2 Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn='data/geospatial', layer='CyclingPathGazette')\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\nkable(head(cyclingpath, n = 3))\n\n\n\n\nPLANNING_A\nPLANNING_1\ngeometry\n\n\n\n\nNA\nNA\nMULTILINESTRING ((16001.13 …\n\n\nNA\nNA\nMULTILINESTRING ((16012.86 …\n\n\nNA\nNA\nMULTILINESTRING ((16021.49 …\n\n\n\n\n\n\n\n1.4.3 Importing GIS data in kml format\nThe pre-schools-location-kml is in kml format.\n\npreschool = st_read('data/geospatial/pre-schools-location-kml.kml')\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex1\\data\\geospatial\\pre-schools-location-kml.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nNote that preschool is in WSG84 coordinates system (3D).\n\nkable(head(preschool, n = 3))\n\n\n\n\n\n\n\n\n\nName\nDescription\ngeometry\n\n\n\n\nkml_1\n\nPOINT Z (103.7009 1.338325 0)\n\n\nkml_2\n\nPOINT Z (103.8987 1.39044 0)\n\n\nkml_3\n\nPOINT Z (103.8068 1.438017 0)\n\n\n\n\n\n\n\n1.5.1 Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list, of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nclass(mpsz)\n\n[1] \"sf\"         \"data.frame\"\n\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\n1.5.2 Working with glimpse()\nBeside the basic feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\nglimpse(head(mpsz))\n\nRows: 6\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\"\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\"\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\"\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\"\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05,…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913\n$ SHAPE_Area <dbl> 1630379.3, 559816.2, 160807.5, 595428.9, 387429.4, 1030378.8\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (((29092.28 30…\n\n\nglimpse() report reveals the data type of each fields. For example FMEL-UPD_D field is in date data type and X_ADDR, Y_ADDR, SHAPE_L and SHAPE_AREA fields are all in double-precision values.\n\n\n1.5.3 Working with head()\nSometimes we would like to reveal complete information of a feature object, this is the job of head() of Base R\n\nhead(mpsz,3)\n\nSimple feature collection with 3 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 28160.23 ymin: 28369.47 xmax: 32362.39 ymax: 30247.18\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y    MARINA SOUTH         MS\n2        2          1 PEARL'S HILL    OTSZ01      Y          OUTRAM         OT\n3        3          3    BOAT QUAY    SRSZ03      Y SINGAPORE RIVER         SR\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n2 CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06 29782.05\n3 CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96 29974.66\n  SHAPE_Leng SHAPE_Area                       geometry\n1   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3   1740.926   160807.5 MULTIPOLYGON (((29932.33 29..."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. One of the ways is to use the plot() of R Graphic.\n\nplot(mpsz)\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry (multi-polygon) by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"REGION_N\"])\n\n\n\n\n\n\n\n\n\n\nNote: plot() is mean for plotting the geospatial object for quick look. For high cartographic quality plot, other R package such as tmap should be used."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#working-with-projection",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#working-with-projection",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\nCommon issues:\n\ncoordinate system of the source data was missing (such as due to missing .proj for ESRI shapefile)\nwrongly assigned during the importing process\n\nUsing the st_crs() to check in detail of the mpszreveals that although it claims to be in svy21 (singapore proj sys), reading until end of print shows that it is wrongly in EPSG9001 (singapore uses epsg3414)\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 <- st_transform(mpsz, 3414)\n\nRecheck\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21 (EPSG3414).\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system (3D) to projected coordinate system (2D). This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system (3D).\n\nst_geometry(preschool)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\n\nst_crs(preschool)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nNote that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 <- st_transform(preschool, crs=3414)\n\nRecheck\n\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nNotice that it is in svy21 projected coordinate system now. Furthermore, if we refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.8 Importing and Converting An Aspatial Data",
    "text": "1.8 Importing and Converting An Aspatial Data\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- (long) and y-coordinates (lat) of the data points.\nIn this section, we will learn how to\n\nimport an aspatial data into R environment and save it as a tibble data frame\nconvert it into a simple feature data frame.\n\nThe listings.csv data downloaded from AirBnb will be used.\n\n1.8.1 Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings <- read_csv('data/aspatial/listings.csv')\nclass(listings)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,161 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    <dbl> <chr>       <dbl> <chr>     <chr>               <chr>            <dbl>\n 1  50646 Pleasant…  227796 Sujatha   Central Region      Bukit Timah       1.33\n 2  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 3  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 4  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Cozy Blu… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330089 Cozy Blu… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 330095 10 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n# ℹ 4,151 more rows\n# ℹ 11 more variables: longitude <dbl>, room_type <chr>, price <dbl>,\n#   minimum_nights <dbl>, number_of_reviews <dbl>, last_review <date>,\n#   reviews_per_month <dbl>, calculated_host_listings_count <dbl>,\n#   availability_365 <dbl>, number_of_reviews_ltm <dbl>, license <chr>\n\n\nOther ways of displaying tabular data in R:\n\nkablegtDT (interactive table)\n\n\n\nkable(head(listings))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nhost_id\nhost_name\nneighbourhood_group\nneighbourhood\nlatitude\nlongitude\nroom_type\nprice\nminimum_nights\nnumber_of_reviews\nlast_review\nreviews_per_month\ncalculated_host_listings_count\navailability_365\nnumber_of_reviews_ltm\nlicense\n\n\n\n\n50646\nPleasant Room along Bukit Timah\n227796\nSujatha\nCentral Region\nBukit Timah\n1.33432\n103.7852\nPrivate room\n80\n92\n18\n2014-12-26\n0.18\n1\n365\n0\nNA\n\n\n71609\nEnsuite Room (Room 1 & 2) near EXPO\n367042\nBelinda\nEast Region\nTampines\n1.34537\n103.9589\nPrivate room\n145\n92\n20\n2020-01-17\n0.15\n6\n340\n0\nNA\n\n\n71896\nB&B Room 1 near Airport & EXPO\n367042\nBelinda\nEast Region\nTampines\n1.34754\n103.9596\nPrivate room\n85\n92\n24\n2019-10-13\n0.18\n6\n265\n0\nNA\n\n\n71903\nRoom 2-near Airport & EXPO\n367042\nBelinda\nEast Region\nTampines\n1.34531\n103.9610\nPrivate room\n85\n92\n47\n2020-01-09\n0.34\n6\n365\n0\nNA\n\n\n275344\n15 mins to Outram MRT Single Room\n1439258\nKay\nCentral Region\nBukit Merah\n1.28836\n103.8114\nPrivate room\n49\n60\n14\n2022-07-09\n0.11\n44\n296\n1\nS0399\n\n\n289234\nBooking for 3 bedrooms\n367042\nBelinda\nEast Region\nTampines\n1.34490\n103.9598\nPrivate room\n184\n92\n12\n2019-01-01\n0.10\n6\n285\n0\nNA\n\n\n\n\n\n\n\n\nlibrary(gt)\nhead(listings) %>% gt() %>% tab_header(title = \"AirBnB listings\")\n\n\n\n\n\n  \n    \n      AirBnB listings\n    \n    \n    \n      id\n      name\n      host_id\n      host_name\n      neighbourhood_group\n      neighbourhood\n      latitude\n      longitude\n      room_type\n      price\n      minimum_nights\n      number_of_reviews\n      last_review\n      reviews_per_month\n      calculated_host_listings_count\n      availability_365\n      number_of_reviews_ltm\n      license\n    \n  \n  \n    50646\nPleasant Room along Bukit Timah\n227796\nSujatha\nCentral Region\nBukit Timah\n1.33432\n103.7852\nPrivate room\n80\n92\n18\n2014-12-26\n0.18\n1\n365\n0\nNA\n    71609\nEnsuite Room (Room 1 & 2) near EXPO\n367042\nBelinda\nEast Region\nTampines\n1.34537\n103.9589\nPrivate room\n145\n92\n20\n2020-01-17\n0.15\n6\n340\n0\nNA\n    71896\nB&B  Room 1 near Airport & EXPO\n367042\nBelinda\nEast Region\nTampines\n1.34754\n103.9596\nPrivate room\n85\n92\n24\n2019-10-13\n0.18\n6\n265\n0\nNA\n    71903\nRoom 2-near Airport & EXPO\n367042\nBelinda\nEast Region\nTampines\n1.34531\n103.9610\nPrivate room\n85\n92\n47\n2020-01-09\n0.34\n6\n365\n0\nNA\n    275344\n15 mins to Outram MRT Single Room\n1439258\nKay\nCentral Region\nBukit Merah\n1.28836\n103.8114\nPrivate room\n49\n60\n14\n2022-07-09\n0.11\n44\n296\n1\nS0399\n    289234\nBooking for 3 bedrooms\n367042\nBelinda\nEast Region\nTampines\n1.34490\n103.9598\nPrivate room\n184\n92\n12\n2019-01-01\n0.10\n6\n285\n0\nNA\n  \n  \n  \n\n\n\n\n\n\n\nlibrary(DT)\ndatatable(head(listings), class = 'cell-border stripe', options = list(pageLength = 3))\n\n\n\n\nTwo useful fields we need are latitude and longitude and they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n1.8.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\nEPSG 4326 is associated with WGS84.\n\nlistings_sf <- st_as_sf(listings,\n                        coords = c('longitude','latitude'),\n                        crs=4326) %>%\n  st_transform(crs=3414)\n\nclass(listings_sf)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n\nLet us examine the content of our newly created sf dataframe\n\nglimpse(listings_sf)\n\nRows: 4,161\nColumns: 17\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275344, 289…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 145, 85, 85, 49, 184, 79, 49, 55, 5…\n$ minimum_nights                 <dbl> 92, 92, 92, 92, 60, 92, 92, 60, 60, 60,…\n$ number_of_reviews              <dbl> 18, 20, 24, 47, 14, 12, 133, 17, 12, 3,…\n$ last_review                    <date> 2014-12-26, 2020-01-17, 2019-10-13, 20…\n$ reviews_per_month              <dbl> 0.18, 0.15, 0.18, 0.34, 0.11, 0.10, 1.0…\n$ calculated_host_listings_count <dbl> 1, 6, 6, 6, 44, 6, 7, 44, 44, 44, 6, 7,…\n$ availability_365               <dbl> 365, 340, 265, 365, 296, 285, 365, 181,…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 1, 0, 0, …\n$ license                        <chr> NA, NA, NA, NA, \"S0399\", NA, NA, \"S0399…\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…\n\n\nA new column geometry has been added at the back of the df. Additionally, lat long columns were both dropped from the df."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.9 Geoprocessing with sf package",
    "text": "1.9 Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, we will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n1.9.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nA buffer is a zone around a spatial object, recall that cyclingpath is a multiline-string sf object.\n\nst_geometry(cyclingpath)\n\nGeometry set for 2248 features \nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cyclingpath .\n\nbuffer_cycling <- st_buffer(cyclingpath,\n                            dist = 5,\n                            nQuadSegs = 30)\n\nTake a peak at this df before calculating area.\n\nhead(buffer_cycling)\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 15867.37 ymin: 36795.67 xmax: 16026.95 ymax: 36953.73\nProjected CRS: SVY21\n  PLANNING_A PLANNING_1                       geometry\n1       <NA>       <NA> POLYGON ((16004.15 36799.78...\n2       <NA>       <NA> POLYGON ((16013.15 36849.86...\n3       <NA>       <NA> POLYGON ((16016.91 36892.98...\n4       <NA>       <NA> POLYGON ((16017.59 36864, 1...\n5       <NA>       <NA> POLYGON ((16022.36 36900.57...\n6       <NA>       <NA> POLYGON ((15903.87 36941.12...\n\n\nNow, we will calculate the area of the buffers as shown in the code chunk below.\nWe are also adding a derived column to buffer_cycling too.\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\nkable(head(buffer_cycling))\n\n\n\n\n\n\n\n\n\n\nPLANNING_A\nPLANNING_1\ngeometry\nAREA\n\n\n\n\nNA\nNA\nPOLYGON ((16004.15 36799.78…\n186.2934 [m^2]\n\n\nNA\nNA\nPOLYGON ((16013.15 36849.86…\n293.4840 [m^2]\n\n\nNA\nNA\nPOLYGON ((16016.91 36892.98…\n284.8275 [m^2]\n\n\nNA\nNA\nPOLYGON ((16017.59 36864, 1…\n144.8915 [m^2]\n\n\nNA\nNA\nPOLYGON ((16022.36 36900.57…\n281.2016 [m^2]\n\n\nNA\nNA\nPOLYGON ((15903.87 36941.12…\n398.7081 [m^2]\n\n\n\n\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]\n\n\nGood Job!\nMission Accomplished!\n\n\n1.9.2 Point-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nBefore that, lets double confirm both data are using same projection system.\n\nidentical(st_crs(mpsz3414), st_crs(preschool3414))\n\n[1] TRUE\n\n\nThe solution:\nThe code chunk below performs two operations at one go.\n\nidentify pre-schools located inside each Planning Subzone by using st_intersects().\nlength() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414,preschool3414))\n\n\n\n\n\n\n\nst_intersects(): count points in polygon\nst_intersection(): find polygon areas overlap\n\n\n\nNow check summary stats of PreSch Count column in each subzone.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package can be used.\n\nkable(top_n(mpsz3414, 3, `PreSch Count`) %>%\n        arrange(desc(`PreSch Count`)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nSUBZONE_NO\nSUBZONE_N\nSUBZONE_C\nCA_IND\nPLN_AREA_N\nPLN_AREA_C\nREGION_N\nREGION_C\nINC_CRC\nFMEL_UPD_D\nX_ADDR\nY_ADDR\nSHAPE_Leng\nSHAPE_Area\nPreSch Count\ngeometry\n\n\n\n\n189\n2\nTAMPINES EAST\nTMSZ02\nN\nTAMPINES\nTM\nEAST REGION\nER\n21658EAAF84F4D8D\n2014-12-05\n41122.55\n37392.39\n10180.624\n4339824\n58\nMULTIPOLYGON (((42196.76 38…\n\n\n290\n3\nWOODLANDS EAST\nWDSZ03\nN\nWOODLANDS\nWD\nNORTH REGION\nNR\nC90769E43EE6B0F2\n2014-12-05\n24506.64\n46991.63\n6603.608\n2553464\n47\nMULTIPOLYGON (((24786.75 46…\n\n\n199\n4\nBEDOK NORTH\nBDSZ04\nN\nBEDOK\nBD\nEAST REGION\nER\nA2254301F85C1EDF\n2014-12-05\n39429.21\n34737.62\n8414.962\n3203663\n31\nMULTIPOLYGON (((40284.24 35…\n\n\n\n\n\nTo calculate the density (# schools/subzone area) of preschool by planning subzone :\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(AREA = st_area(mpsz3414),\n         DENSITY = `PreSch Count` /AREA * 1000000) %>% \n  arrange(desc(DENSITY))\n\nkable(head(mpsz3414))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nSUBZONE_NO\nSUBZONE_N\nSUBZONE_C\nCA_IND\nPLN_AREA_N\nPLN_AREA_C\nREGION_N\nREGION_C\nINC_CRC\nFMEL_UPD_D\nX_ADDR\nY_ADDR\nSHAPE_Leng\nSHAPE_Area\nPreSch Count\nAREA\nDENSITY\ngeometry\n\n\n\n\n27\n8\nCECIL\nDTSZ08\nY\nDOWNTOWN CORE\nDT\nCENTRAL REGION\nCR\n65AA82AF6F4D925D\n2014-12-05\n29730.20\n29011.33\n2116.0947\n196619.86\n7\n196619.86 [m^2]\n35.60169 [1/m^2]\nMULTIPOLYGON (((29808.18 28…\n\n\n278\n3\nMANDAI ESTATE\nMDSZ03\nN\nMANDAI\nMD\nNORTH REGION\nNR\nF6266F7368DBB9AB\n2014-12-05\n27082.70\n45367.46\n1633.7084\n143137.94\n5\n143137.94 [m^2]\n34.93134 [1/m^2]\nMULTIPOLYGON (((27119.56 45…\n\n\n37\n4\nPHILLIP\nDTSZ04\nY\nDOWNTOWN CORE\nDT\nCENTRAL REGION\nCR\n615D4EDDEF809F8E\n2014-12-05\n29706.72\n29744.91\n871.5549\n39437.94\n1\n39437.94 [m^2]\n25.35630 [1/m^2]\nMULTIPOLYGON (((29814.11 29…\n\n\n291\n3\nSEMBAWANG CENTRAL\nSBSZ03\nN\nSEMBAWANG\nSB\nNORTH REGION\nNR\n772A64AB9A93FC3A\n2014-12-05\n26268.73\n47558.08\n3955.1176\n962437.40\n23\n962437.40 [m^2]\n23.89766 [1/m^2]\nMULTIPOLYGON (((26311.14 46…\n\n\n253\n3\nSERANGOON NORTH\nSGSZ03\nN\nSERANGOON\nSG\nNORTH-EAST REGION\nNER\nC685042EC58E5C55\n2014-12-05\n32458.80\n39597.64\n3610.7324\n684704.30\n15\n684704.30 [m^2]\n21.90727 [1/m^2]\nMULTIPOLYGON (((32860.5 397…\n\n\n272\n3\nSENGKANG TOWN CENTRE\nSESZ03\nN\nSENGKANG\nSE\nNORTH-EAST REGION\nNER\n5A2D0E9E6B285069\n2014-12-05\n35163.81\n41501.14\n5216.4005\n1455507.86\n30\n1455507.86 [m^2]\n20.61136 [1/m^2]\nMULTIPOLYGON (((35615.75 40…\n\n\n\n\n\nThe table above shows the top 6 highest density subzones ."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#explorotary-data-analysis-eda",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#explorotary-data-analysis-eda",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "1.10 Explorotary Data Analysis (EDA)",
    "text": "1.10 Explorotary Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, wewill learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$DENSITY)\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nStaticInteractive (plotly)\n\n\n\nq <- quantile(as.numeric(mpsz3414$DENSITY), probs = c(0.25, 0.5, 0.75))\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(DENSITY)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(xintercept = q[2]+1, linetype='dashed', size = 0.5, color='blue') +\n  geom_vline(xintercept = q[3]+1, linetype='dashed', size = 0.5) +\n  annotate('text' , x= 4, y=75, label='50th \\npercentile', size = 2) +\n  annotate('text' , x= 9, y=75, label='75th \\npercentile', size = 2) +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\nlibrary(plotly)\nq <- quantile(as.numeric(mpsz3414$DENSITY), probs = c(0.25, 0.5, 0.75))\n\np <- ggplot(data=mpsz3414, \n       aes(x= as.numeric(DENSITY)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(xintercept = q[2]+1, linetype='dashed', size = 0.5, color='blue') +\n  geom_vline(xintercept = q[3]+1, linetype='dashed', size = 0.5) +\n  annotate('text' , x= 4, y=75, label='50th \\npercentile', size = 2) +\n  annotate('text' , x= 9, y=75, label='75th \\npercentile', size = 2) +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\nggplotly(p)\n\n\n\n\n\n\n\n\nDIY: Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(DENSITY)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_1.html#theories",
    "href": "Hands-on_Ex1/Hands-on_Ex1_1.html#theories",
    "title": "Hands-on Exercise 1.1: Geospatial Data Wrangling with R",
    "section": "Theories",
    "text": "Theories\n\nKML and shapefiles\nA KMZ file is a zipped (or compressed) KML file, and a SHZ is a zipped/compressed Shapefile.\nA shapefile is an Esri vector data storage format for storing the location, shape, and attributes of geographic features. It is stored as a set of related files and contains one feature class.\nThe shapefile format can spatially describe vector features: points, lines, and polygons, representing, for example, water wells, rivers, and lakes. Each item usually has attributes that describe it, such as name or temperature.\nKML and Shapefiles could contain the exact same data, however KML (Keyhole Markup Language) is much more suited to displaying time based track information, whereas shapefiles are more suited to displaying Geometries, like boundaries, areas, roads, etc.\nShapefiles are composed of 3 mandatory files\n·       . shp (geometry), <- multipolygon, polylines or points. Can only be one type in each file , can combined in layers\n·       . dbf (attributes) <- table\n·       . shx (index)  <- binds first two together\n\n\nGCS [Geographic Coordinate System] (3D) and PCS [Projected Coordinate System ] (2D)\nGCS: uses lat, long, elevation to locate positions on Earth. Units are in degree and metres. Earth is represented as a sphere. Eg. WGS84 (world Gedetic system 1984)\nPCS: Units are usually metres to locate position on a Flat surface. Involves projecting 3D Earth into a 2D plane. It distorts the true shapes, areas, distances, or directions to some extent, depending on the projection method chosen.\nPreserve:\n·       Conformal projections minimize distortion in shape\n·       Equidistant projections minimize distortion in distance\n·       Equal-area projection minimize distortion in area\n·       Azimuthal or True-direction projections minimize distortion in direction.\nGoogle maps uses Mercator projection system. It is chosen as it preserves direction and angles. It is useful for navigation (google map) . It is originally created for sea navigation in older days. The cons are that this projection does not preserve area and shape.\nSingapore uses SVY21 or the EPSG:3414 projected coordinate system.\n\n\nGeospatial data handling functions\n\nst_read & read sf: read simple features from file or database, or retrieve layer names and their geometry type(s)\nst write &write_sf: write simple features object to file or database\nst_as_sf: convert a sf object from a non-geospatial tabular data frame\nst as_text: convert to Well Known Text(WKT)\nst as_binary: convert to Well Known Binary(WKB)\nst_as_sfc: convert geometries to sfc (e.g., from WKT, WKB) as(x, “Spatial”): convert to Spatial*\nst transform(x, crs, …): convert coordinates of x to a different coordinate reference system\n\nThe code chunk below allows us to unsf the mpsz and work tbl_df or data.frame.\n\nmpsz_tbl_df <- as_tibble(mpsz)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_2.html",
    "href": "Hands-on_Ex1/Hands-on_Ex1_2.html",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_2.html#getting-started",
    "href": "Hands-on_Ex1/Hands-on_Ex1_2.html#getting-started",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\nIn this hands-on exercise, we learn how to plot functional and truthful choropleth maps by using r packages called tmap package.\nBeside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nLets us first load all the required libraries.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_2.html#importing-data-into-r",
    "href": "Hands-on_Ex1/Hands-on_Ex1_2.html#importing-data-into-r",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "2.3 Importing Data into R",
    "text": "2.3 Importing Data into R\n\n2.3.1 The Data\nThe Two datasets will be used to create the choropleth map are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore, the specific link can be found here. Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n2.3.2 Importing Geospatial Data into R\n\nmpsz <- st_read(dsn='data/geospatial',\n                layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex1\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nCheck the projection system of mpsz. It is not in svy21 or epsg3414. We will need to convert it later.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nTake a look at first few records of data\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nLets convert to EPSG3414 now.\n\nmpsz3414 <- st_transform(mpsz, 3414)\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nhead(mpsz3414,3)\n\nSimple feature collection with 3 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 28160.23 ymin: 28369.47 xmax: 32362.39 ymax: 30247.18\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO    SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N PLN_AREA_C\n1        1          1 MARINA SOUTH    MSSZ01      Y    MARINA SOUTH         MS\n2        2          1 PEARL'S HILL    OTSZ01      Y          OUTRAM         OT\n3        3          3    BOAT QUAY    SRSZ03      Y SINGAPORE RIVER         SR\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84 29220.19\n2 CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06 29782.05\n3 CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96 29974.66\n  SHAPE_Leng SHAPE_Area                       geometry\n1   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n\n\n\n\n2.3.3 Importing Attribute Data into R\nNext, we will import respopagsex2000to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\nhead(popdata)\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  <chr>      <chr>                  <chr>  <chr> <chr>               <dbl> <dbl>\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2011\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats       10  2011\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       30  2011\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    50  2011\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2011\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Landed Properties       0  2011\n\n\nSummary stats using skimr package.\n\nlibrary(skimr)\nskim(popdata)\n\n\nData summary\n\n\nName\npopdata\n\n\nNumber of rows\n984656\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nPA\n0\n1\n4\n23\n0\n55\n0\n\n\nSZ\n0\n1\n4\n29\n0\n335\n0\n\n\nAG\n0\n1\n6\n11\n0\n19\n0\n\n\nSex\n0\n1\n5\n7\n0\n2\n0\n\n\nTOD\n0\n1\n6\n39\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPop\n0\n1\n39.86\n132.25\n0\n0\n0\n10\n2860\n▇▁▁▁▁\n\n\nTime\n0\n1\n2015.51\n2.88\n2011\n2013\n2016\n2018\n2020\n▇▇▇▇▇"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_2.html#data-preparation",
    "href": "Hands-on_Ex1/Hands-on_Ex1_2.html#data-preparation",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "2.3.4 Data preparation",
    "text": "2.3.4 Data preparation\nPrepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.3.4.1 Data Wrangling\n\npivot_wider() (rows to column headers) of tidyr package, and\nmutate() (create new cal col), filter() (subset rows), group_by() and select() (select cols) of dplyr package\n\nThe complete code chunk:\n\npopdata2020 <- popdata %>% \n  filter(Time==2020) %>% \n  group_by(PA,SZ,AG) %>%   #<< for calculating POP column below\n  summarise(`POP` = sum(Pop)) %>% \n  ungroup() %>%\n  pivot_wider(names_from = AG,\n              values_from = POP) %>% \n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %>% \n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+rowSums(.[15])) %>%\n  mutate(AGED = rowSums(.[16:21])) %>%\n  mutate(TOTAL = rowSums(.[3:21])) %>% \n  mutate(DEPENDENCY = (YOUNG+AGED)/`ECONOMY ACTIVE`) %>% \n  select(PA, SZ,YOUNG,'ECONOMY ACTIVE', AGED, TOTAL, DEPENDENCY)\n\nhead(popdata2020)\n\n# A tibble: 6 × 7\n  PA         SZ                    YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n  <chr>      <chr>                 <dbl>            <dbl> <dbl> <dbl>      <dbl>\n1 Ang Mo Kio Ang Mo Kio Town Cent…  1290             2760   760  4810      0.743\n2 Ang Mo Kio Cheng San              5640            16460  6050 28150      0.710\n3 Ang Mo Kio Chong Boon             5100            15000  6470 26570      0.771\n4 Ang Mo Kio Kebun Bahru            4620            13010  5120 22750      0.749\n5 Ang Mo Kio Sembawang Hills        1880             3630  1310  6820      0.879\n6 Ang Mo Kio Shangri-La             3330             9050  3610 15990      0.767\n\n\nTo understand the first 6 lines of code in the code chunk above, print the output:\n\n\n# A tibble: 6 × 21\n  PA       SZ    `0_to_4` `10_to_14` `15_to_19` `20_to_24` `25_to_29` `30_to_34`\n  <chr>    <chr>    <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n1 Ang Mo … Ang …      170        280        340        270        260        310\n2 Ang Mo … Chen…     1060       1040       1160       1330       1720       2020\n3 Ang Mo … Chon…      850       1020       1070       1310       1610       1890\n4 Ang Mo … Kebu…      680        960       1010       1170       1410       1420\n5 Ang Mo … Semb…      210        400        450        500        500        340\n6 Ang Mo … Shan…      560        640        700        860        970       1030\n# ℹ 13 more variables: `35_to_39` <dbl>, `40_to_44` <dbl>, `45_to_49` <dbl>,\n#   `50_to_54` <dbl>, `55_to_59` <dbl>, `5_to_9` <dbl>, `60_to_64` <dbl>,\n#   `65_to_69` <dbl>, `70_to_74` <dbl>, `75_to_79` <dbl>, `80_to_84` <dbl>,\n#   `85_to_89` <dbl>, `90_and_over` <dbl>\n\n\n\n2.3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\nSince mpsz’s SUBZONE_N and PLN_AREA_N are in uppercase, we have to convert PA and SZ fields in popdata2020 into all uppercase using:\n\nmutate.at()<- mutate multiple columns\nfirst argument of mutate_at(): .var <- list of columns generated by vars()\nsecond argument: .funs <- a function fun, a quosure style lambda. The function used in toupper() <- to upper case\n\nThere are many ways to achieve the final output\n\nProf’s bookAlternative\n\n\n\npopdata2020 <- popdata2020 %>% \n  mutate_at(.vars= vars(PA, SZ),\n            .funs = funs(toupper)) %>% \n  filter(`ECONOMY ACTIVE` >0)\n\npopdata2020\n\n# A tibble: 234 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   <chr>      <chr>                <dbl>            <dbl> <dbl> <dbl>      <dbl>\n 1 ANG MO KIO ANG MO KIO TOWN CEN…  1290             2760   760  4810      0.743\n 2 ANG MO KIO CHENG SAN             5640            16460  6050 28150      0.710\n 3 ANG MO KIO CHONG BOON            5100            15000  6470 26570      0.771\n 4 ANG MO KIO KEBUN BAHRU           4620            13010  5120 22750      0.749\n 5 ANG MO KIO SEMBAWANG HILLS       1880             3630  1310  6820      0.879\n 6 ANG MO KIO SHANGRI-LA            3330             9050  3610 15990      0.767\n 7 ANG MO KIO TAGORE                1940             4480  1530  7950      0.775\n 8 ANG MO KIO TOWNSVILLE            4190            11950  5100 21240      0.777\n 9 ANG MO KIO YIO CHU KANG EAST     1110             2410   750  4270      0.772\n10 ANG MO KIO YIO CHU KANG WEST     5690            13750  4680 24120      0.754\n# ℹ 224 more rows\n\n\nThe reason for filtering is because some subzones are not inhibited by residents as seen below.\n\n\n\npopdata2020 %>%\n  mutate(PA = toupper(PA),\n         SZ = toupper(SZ)) %>% \n  filter(`ECONOMY ACTIVE` >0)\n\n\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <-left_join(mpsz3414, popdata2020,\n                         by = c('SUBZONE_N' = 'SZ'))\nmpsz_pop2020\n\nSimple feature collection with 323 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area              PA YOUNG ECONOMY ACTIVE AGED\n1  29220.19   5267.381  1630379.3            <NA>    NA             NA   NA\n2  29782.05   3506.107   559816.2          OUTRAM   930           3130 2120\n3  29974.66   1740.926   160807.5 SINGAPORE RIVER     0             40   10\n4  29933.77   3313.625   595428.9     BUKIT MERAH  2600           7450 3320\n5  30005.70   2825.594   387429.4     BUKIT MERAH  2760           6160 1740\n6  29991.38   4428.913  1030378.8     BUKIT MERAH  2800           7340 3420\n7  30230.86   3275.312   551732.0     BUKIT MERAH  2750           8080 3610\n8  30222.86   2208.619   290184.7 SINGAPORE RIVER     0             50   10\n9  29893.78   6571.323  1084792.3      QUEENSTOWN  1120           2770  610\n10 30104.18   3454.239   631644.3      QUEENSTOWN    30            160   60\n   TOTAL DEPENDENCY                       geometry\n1     NA         NA MULTIPOLYGON (((31495.56 30...\n2   6180  0.9744409 MULTIPOLYGON (((29092.28 30...\n3     50  0.2500000 MULTIPOLYGON (((29932.33 29...\n4  13370  0.7946309 MULTIPOLYGON (((27131.28 30...\n5  10660  0.7305195 MULTIPOLYGON (((26451.03 30...\n6  13560  0.8474114 MULTIPOLYGON (((25899.7 297...\n7  14440  0.7871287 MULTIPOLYGON (((27746.95 30...\n8     60  0.2000000 MULTIPOLYGON (((29351.26 29...\n9   4500  0.6245487 MULTIPOLYGON (((20996.49 30...\n10   250  0.5625000 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\n\n\n\nImportant\n\n\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nOriginal # rows in mpsz3414 = 323\nOriginal # of rows in popdata2022 = 234\nFinal # of rows in mpsz_pop2020 = 323\nWrite the data as rds, can preserve the format of data.\n\n# write_rds(mpsz_pop2020, 'data/rds/mpszpop2020.rds')\n# mpsz_pop2020 <- readRDS('data/rds/mpszpop2020.rds')\n\nLets take a look at the df mpsz_pop2020"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_2.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex1/Hands-on_Ex1_2.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "2.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.4 Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\n\ntmap_mode('plot')\n#tmap_mode('view')\n#ttm()\n#last_map()\n#tmap_options(check.and.fix = TRUE)\n\nqtm(mpsz_pop2020,\n    fill='DEPENDENCY')\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n2.4.2 Creating a Choropleth map by using tmap’s elements\ntmap’ drawing elements (unlike qtm() ) is able to give us finer control over our chloropleth map.\ntm_shape() <- define input data and specify the shape object / spatial data object\ntm_fill() <- fills polygons (no border)\n\nstyle: method to process the color scale when col (data variable) is a numeric variable. To process numeric and categorical use “cat”\npalette : palettes names or vectors of colors. default is taken from tm_layout’s aes.paletttes argument. To reverse the colour scheme , add a “-” prefix.\n\ntm_borders() <- draws the borders of polygons (alpha is 0-1, transparency)\ntm_polygons() (= tm_fill() + tm_borders() )<- fills the polygon and draws the polygon borders\n*qtm = shape + polygon or * qtm = shape + fill + border\ntm_layout() <- specify map layout\n\naes.palette <- ‘seq’ (sequential palettes), ‘div’ (diverging palettes) , ‘cat’ (categorical palettes)\n\ntm_compass() <- create map compass\ntm_scale_bar() <- creates scale bar\ntm_grid() <- creates grid lines (alpha is 0-1, transparency of grid lines)\ntm_credits() <- create a text for credits\n\nHigh quality graphmpsz_pop2020 table\n\n\n\n\nShow the code\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nlibrary(knitr)\nkable(head(mpsz_pop2020,3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBJECTID\nSUBZONE_NO\nSUBZONE_N\nSUBZONE_C\nCA_IND\nPLN_AREA_N\nPLN_AREA_C\nREGION_N\nREGION_C\nINC_CRC\nFMEL_UPD_D\nX_ADDR\nY_ADDR\nSHAPE_Leng\nSHAPE_Area\nPA\nYOUNG\nECONOMY ACTIVE\nAGED\nTOTAL\nDEPENDENCY\ngeometry\n\n\n\n\n1\n1\nMARINA SOUTH\nMSSZ01\nY\nMARINA SOUTH\nMS\nCENTRAL REGION\nCR\n5ED7EB253F99252E\n2014-12-05\n31595.84\n29220.19\n5267.381\n1630379.3\nNA\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((31495.56 30…\n\n\n2\n1\nPEARL’S HILL\nOTSZ01\nY\nOUTRAM\nOT\nCENTRAL REGION\nCR\n8C7149B9EB32EEFC\n2014-12-05\n28679.06\n29782.05\n3506.107\n559816.2\nOUTRAM\n930\n3130\n2120\n6180\n0.9744409\nMULTIPOLYGON (((29092.28 30…\n\n\n3\n3\nBOAT QUAY\nSRSZ03\nY\nSINGAPORE RIVER\nSR\nCENTRAL REGION\nCR\nC35FEFF02B13E0E5\n2014-12-05\n29654.96\n29974.66\n1740.926\n160807.5\nSINGAPORE RIVER\n0\n40\n10\n50\n0.2500000\nMULTIPOLYGON (((29932.33 29…\n\n\n\n\n\n\n\n\n\n2.4.2.1 Drawing a base map\nBasic building blocks are tm_fill() and tm_polygons().\ntm_polygons() = fill + borders\n\ntm_borders()tm_fill()\n\n\nBase Map\n\ntm_shape(mpsz_pop2020) +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\nTo show the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY')\n\n\n\n\n\n\n\n\n\n2.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\nNo variableWith variable\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n2.4.2.3 Drawing a choropleth map using tm_fill() + *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nApart from alpha (transparency number 0 - 1), other arguments are\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n2.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.4.3.1 Plotting choropleth maps with built-in classification methods\nThe codes below uses quantile classification with 5 classes.\n\nfill + borderpolygons\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing equal classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDistribution of quantile data classification method are more evenly distributed then equal data classification method.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",n = 5,\n          style = \"jenks\" )\n\n\n\n\n\n\n\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\nUsing tmap_arrange:\n\nkmeans<- tm_shape(mpsz_pop2020)+\n    tm_fill(\"DEPENDENCY\", n = 5, style = 'kmeans') +\n  tm_borders(alpha = 0.5)\n\nsd <- tm_shape(mpsz_pop2020)+\n    tm_fill(\"DEPENDENCY\", n = 5, style = 'sd') +\n  tm_borders(alpha = 0.5)\n\nfisher <- tm_shape(mpsz_pop2020)+\n    tm_fill(\"DEPENDENCY\", n = 5, style = 'fisher') +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(kmeans, sd, fisher, asp = 4, nrow=3)\n\n\n\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\nAssigning multiple values to at least one of the aesthetics arguments.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c('DEPENDENCY','DEPENDENCY'),\n          style= c('jenks','jenks'),\n          n = c(3,10),\n          palette= list('Greens', 'Greens')) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.position = c('right','bottom'),\n            legend.width = 0.5,\n            legend.height = 0.4,\n            legend.text.size = 0.35 )\n\n\n\n\n\n\n2.4.3.2 Plotting choropleth maps with custome break\nThe breakpoints can be set explicitly by means of the breaks argument to the tm_fill().\n\nbreaks include min and max\nto have n categories, n+1 elements to be specified in breaks option\nvalues must be in increasing order\n\nGood practise: descriptive statistics on variable before setting break points\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to summary stats and boxplot above,\n\nbreak points are 0.6, 0.7, 0.8, 0.9\nmin = 0 and max = 1.0\nbreak vector is thus c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", breaks = c(0, 0.6, 0.7, 0.8, 0.9, 1.0)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n2.4.4 Colour scheme\n\n2.4.4.1 Using ColourBrewer palette (predefined)\n(YIOrRd, YIORrBr, YIGnBu, YIGn, Reds, RdPu, Purples, PuRd, PuBuGn, PuBu, OrRd, Oranges, Greys, Greens, GnBu, BuPu, BuGn, Blues)\n\n\n\n\n\nAssign the preferred colour to palette argument of tm_fill()\n\nnormalreverse\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nReverse the colour scheme by adding “-”\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.4.5 Map Layouts\n\ncustomise title, scale bar, compass, margins, aspect ratios\nother than colour palette and data classification (breaks) which is done in tm_fill()\n\n\n2.4.5.1 Map Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style()\nPredefined styles: ‘white’, ‘gray’, ‘natural’, ‘bw’, ‘classic’, ‘cobalt’, albatross’, ‘beaver’, ‘col_blind’, ‘watercolor’\nBelow is an example of classic style\n\ngraynaturalbwclassiccobaltbeaver\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)+\n  tmap_style('gray')\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)+\n  tmap_style('natural')\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)+\n  tmap_style('bw')\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)+\n  tmap_style('classic')\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-RdPu\") +\n  tm_borders(alpha = 0.5)+\n  tmap_style('cobalt')\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Purples\") +\n  tm_borders(alpha = 0.5)+\n  tmap_style('beaver')\n\n\n\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\nCan include other map furniture like compass, scale bar, and grid lines\ntmap_style has to be used at the last, think cannot mix with tm\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Reds\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\")) +\n  tmap_style('natural')\n\n\n\n\nTo reset the default style, refer below\n\ntmap_style(\"white\")\n\n\n\n\n2.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nSmall multiple choropleth maps are created by\n\n2.4.6.1.1 Defining ncols in tm_fill() : c(‘YOUNG’, ‘AGED’)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.height = 0.35, \n            legend.width = 0.35) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n2.4.6.1.2 Assigning multiple values to at least one of the aesthetic arguments\n\nshape + polygon method (Prof’s)\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.height = 0.35, \n            legend.width = 0.35) +\n  tmap_style('white')\n\n\n\n\n\n\n\n\nshape + fill + borders method (NYX’s)\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c('YOUNG', 'AGED','TOTAL'),\n          style=c('equal', 'quantile', 'equal'),\n          palette= list('Blues', 'Greens', 'Reds')) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(legend.position = c('right','bottom'),\n            legend.height = 0.35, \n            legend.width = 0.35)\n\n\n\n\n\n\n\n2.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\nthres.poly: number that specifies the threshold at which polygons are taken into account. The number itself corresponds to the proportion of the area sizes of the polygons to the total polygon size. By default, all polygons are drawn.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nCreating multiple stand-alone maps with tmap_arrange() asp : aspect ratio\nnrow : number of rows (ncols)\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\") +\n  tm_layout(legend.position = c('right','bottom'),\n          legend.height = 0.5, \n          legend.width = 0.35)\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\") +\n  tm_layout(legend.position = c('right','bottom'),\n        legend.height = 0.5, \n        legend.width = 0.35)\n\ntmap_arrange(youngmap, agedmap, asp=3, ncol=1, nrow=2)\n\n\n\n\n\n\n\n2.4.7 Mappping Spatial Object Meeting a Selection Criterion\nUse selection funtion to map spatial objects meeting the selection criterion. The comma , is used to indicate that we want to select all columns for the rows that meet the condition.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.3) +\n  tm_layout(main.title = \"Mapping spatial obj with conditions \\n(Central Region)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            legend.title.size= 0.8,\n            legend.text.size= 0.6,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE,\n            bg.color = \"mintcream\") + #call colors()\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nWhat to do if legend overlaps with map?\n\n\nreduce legend.text.size or legend.height and legend.width\nadjust inner.margin\n\n\nAdjust background colours with its corresponding text colours.\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons(\"DEPENDENCY\") +\n    tm_layout(main.title = \"Mapping spatial obj with conditions \\n(Central Region)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            #legend.outside = TRUE,\n            legend.height = 0.3, \n            legend.width = 0.3,\n            legend.title.size= 0.8,\n            legend.text.size= 0.6,\n            inner.margins = c(0.01, 0.01, 0, .15), # ensures legend does not overlap with chart c(bottom,top,left,right)\n            frame = FALSE,\n            legend.position = c(\"right\", \"top\"),\n            bg.color = \"black\",\n            main.title.color = 'white',\n            legend.title.color = 'white',\n            legend.text.color= 'white')\n\n\n\n\n\n\n\n\n\n2.4.8. Tmap summary\nFrom chap 2, using tmap package to plot\n1. tm_shape+ tm_polygon\n2. tm_shape+ tm_fill + tm_borders _ tm_layout\n3. qtm\nChap 2: To plot small multiple chloroplath maps via qtm or tmap elements:\n1. Add multiple values to tm_polygon or tm_fill\n2. Tm_facets\n3. Tm_arrange\nChap 3: To plot small multiple layered chloroplath maps via plot() method:\n 4. To arrange the maps via plot(),\npar(mfrow=c(2,2)) <- 2x2 layout\nFrom chap 3: to add layers to a plot\n1. just keep repeating plot(weight matrix ,coords,add=TRUE)\nhttps://rstudio-pubs-static.s3.amazonaws.com/730482_d7889d9c65c8422f843b3d4e0196633c.html"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-on_Ex1_2.html#reference",
    "href": "Hands-on_Ex1/Hands-on_Ex1_2.html#reference",
    "title": "Hands-on Exercise 1.2: Choropleth Mapping with R",
    "section": "2.5 Reference",
    "text": "2.5 Reference\n\n2.5.1 All about tmap package\n\ntmp arguments and defaults : Introduction to Geospatial Visualization with the tmap package\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n2.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n2.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions\n\n\n# there are 111 arguments, run the code below to see the defaults\ntmap_options()"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#the-study-area-and-data",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#the-study-area-and-data",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.2 The Study Area and Data",
    "text": "8.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file (aspatial) contains selected Hunan’s local development indicators in 2012.\n\n\n8.2.1 Getting Started\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.3 Getting the Data Into R Environment",
    "text": "8.3 Getting the Data Into R Environment\n8.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan <- st_read(dsn='data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nclass(hunan)\n\n[1] \"sf\"         \"data.frame\"\n\n\nhunan is in WSG84 coordinate system.\n\nhead(hunan,3) %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nShape_Leng\nShape_Area\nCounty\ngeometry\n\n\n\n\nChangde\n21098\nAnxiang\nCounty\n1.869074\n0.1005619\nAnxiang\nPOLYGON ((112.0625 29.75523…\n\n\nChangde\n21100\nHanshou\nCounty\n2.360691\n0.1997875\nHanshou\nPOLYGON ((112.2288 29.11684…\n\n\nChangde\n21101\nJinshi\nCounty City\n1.425620\n0.0530241\nJinshi\nPOLYGON ((111.8927 29.6013,…\n\n\n\n\n\n\n8.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 <- read_csv('data/aspatial/Hunan_2012.csv')\nhead(hunan2012,3) %>% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCounty\nCity\navg_wage\ndeposite\nFAI\nGov_Rev\nGov_Exp\nGDP\nGDPPC\nGIO\nLoan\nNIPCR\nBed\nEmp\nEmpR\nEmpRT\nPri_Stu\nSec_Stu\nHousehold\nHousehold_R\nNOIP\nPop_R\nRSCG\nPop_T\nAgri\nService\nDisp_Inc\nRORP\nROREmp\n\n\n\n\nAnhua\nYiyang\n30544\n10967.0\n6831.7\n456.72\n2703.0\n13225.0\n14567\n9276.9\n3954.9\n3528.3\n2718\n494.31\n441.4\n338.0\n54.175\n32.830\n290.4\n234.5\n101\n670.3\n5760.6\n910.8\n4942.253\n5414.5\n12373\n0.7359464\n0.8929619\n\n\nAnren\nChenzhou\n28058\n4598.9\n6386.1\n220.57\n1454.7\n4941.2\n12761\n4189.2\n2555.3\n3271.8\n970\n290.82\n255.4\n99.4\n33.171\n17.505\n104.6\n121.9\n34\n243.2\n2386.4\n388.7\n2357.764\n3814.1\n16072\n0.6256753\n0.8782065\n\n\nAnxiang\nChangde\n31935\n5517.2\n3541.0\n243.64\n1779.5\n12482.0\n23667\n5108.9\n2806.9\n7693.7\n1931\n336.39\n270.5\n205.9\n19.584\n17.819\n148.1\n135.4\n53\n346.0\n3957.9\n528.3\n4524.410\n14100.0\n16610\n0.6549309\n0.8041262\n\n\n\n\n\n\n\n8.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\nAs the join columns are not specified, this function will assume that columns with the same names, e.g., ‘county’ in both dfs will be the join columns.\nThe select() will retain the columns indicated in the resulting joined df.\n\nhunan <- left_join(hunan, hunan2012) %>% \n  select(1:4,7,15)\nclass(hunan)\n\n[1] \"sf\"         \"data.frame\"\n\n\nNote the geospatial characteristics of hunan is retained.\n\nhead(hunan,3) %>% kable\n\n\n\n\n\n\n\n\n\n\n\n\n\nNAME_2\nID_3\nNAME_3\nENGTYPE_3\nCounty\nGDPPC\ngeometry\n\n\n\n\nChangde\n21098\nAnxiang\nCounty\nAnxiang\n23667\nPOLYGON ((112.0625 29.75523…\n\n\nChangde\n21100\nHanshou\nCounty\nHanshou\n20981\nPOLYGON ((112.2288 29.11684…\n\n\nChangde\n21101\nJinshi\nCounty City\nJinshi\n34592\nPOLYGON ((111.8927 29.6013,…"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.4 Visualising Regional Development Indicator",
    "text": "8.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap <- tm_shape(hunan)+\n  tm_polygons() +\n  tm_text('NAME_3',\n          size = 0.5)\n\ngdppc <- tm_shape(hunan)+\n  tm_polygons('GDPPC') +\n    tm_layout(legend.height = 0.20, \n            legend.width = 0.25)\n  \n# or gdppc <- qtm(hunan, \"GDPPC\")\n\ntmap_arrange(basemap, gdppc,\n           asp=1,\n           ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.5 Computing Contiguity Spatial Weights",
    "text": "8.5 Computing Contiguity Spatial Weights\nIn this section, we will use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Use this if we know that for a variable, sharing common boundary increases spatial interaction.\nBy default, ‘queen’ argument is set to TRUE: two polygons sharing one shared boundary point will meet contiguity condition. Returns a list of first order neighbours using the Queen criteria.\nIf ‘queen’ argument is set to FALSE: requires more than one shared boundary point. (but may not mean a shared boundary line)\n\n8.5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nwm_q (weights matrix queen) class: ‘nb’\n\nclass(wm_q)\n\n[1] \"nb\"\n\n\nA quick peak at wm_q\n\nhead(wm_q,3)\n\n[[1]]\n[1]  2  3  4 57 85\n\n[[2]]\n[1]  1 57 58 78 85\n\n[[3]]\n[1]  1  4  5 85\n\n\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nPolygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nx1 <- wm_q[[1]]\nhunan$County[c(x1)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nTo display the complete weight matrix, use str()\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n#wm_q[1:10]\n#methods(class = class(wm_q))\n\n\n\n8.5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n8.5.3 Visualising contiguity weights (find centroid coords first)\nA connectivity graph takes a point and displays a line to each neighbouring point.\n\nneed a point in polygon via polygon centroids (its lat & long) <- calculate using the sf package first\n\nTo obtain coordinates in a separate data frame\n\ninput vector is the geometry column of us.bound (in hunan), an sf object <- a polygon\nUsing hunan$geometry[[1]]: The input vector of the FIRST POLYGON looks like POLYGON ((112.0625 29.75523, 112.069 29.74544, 112.0707 29.7415, 112.0716 29.73667, …. , 112.0625 29.75523).\nTo find the centroid (CG) of one polygon, use the st_centroid() function, which is a formula shorthand for a small anonymous function (lambda function). It takes an argument represented by .x. st_centroid(.x)[[1]] extracts the X-coordinate (longitude) of the centroid while st_centroid(.x)[[2]] extracts the Y-coords.\n\nX and YX onlyY only\n\n\n\n#hunan$geometry[[1]]\nst_centroid(hunan$geometry[[1]])\n\n\n\n\nst_centroid(hunan$geometry[[1]])[[1]]\n\n[1] 112.1531\n\n\n\n\n\nst_centroid(hunan$geometry[[1]])[[2]]\n\n[1] 29.44362\n\n\n\n\n\n\nmap_dbl(...) is a function from the purrr package that applies a function to each element of a list or vector and returns the results as a double vector. In this case, the function being applied is the expression following ~. Example of how this function is used in a simple way:\n\n# Example list of vectors\nlist_of_vectors <- list(a = c(1, 2, 3), b = c(4, 5, 6), c = c(7, 8, 9))\n\n# Applying a function to calculate the sum of each vector\nmap_dbl(list_of_vectors, ~ sum(.x))\n\n a  b  c \n 6 15 24 \n\n\nAfter finding centroid, to access longitude values\n\ndouble bracket notation [[ ]] and 1\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlongitude\n\n [1] 112.1531 112.0372 111.8917 111.7031 111.6138 111.0341 113.7065 112.3460\n [9] 112.8169 113.3534 113.8942 112.4006 112.5542 113.6636 112.9206 113.1883\n[17] 113.4521 112.4209 113.0152 112.6350 112.7087 112.9095 111.9522 110.2606\n[25] 110.0921 109.7985 109.5765 109.7211 109.7339 109.1537 110.6442 110.5916\n[33] 109.5984 111.4783 112.1745 111.2315 110.3149 111.3248 110.5859 110.9593\n[41] 111.8296 110.1926 110.7334 110.9123 111.4599 112.5268 112.3406 109.5602\n[49] 109.5071 109.9954 109.4273 109.7587 109.5044 109.9899 109.9664 111.3785\n[57] 112.4350 112.5558 111.7379 112.1831 111.9743 111.7009 112.2196 112.6472\n[65] 113.5102 113.1172 113.7089 112.7963 110.9276 113.6420 113.4577 113.8404\n[73] 113.4758 113.1428 110.3017 113.1957 111.7410 112.1831 111.3390 111.8208\n[81] 110.0753 112.3965 112.7683 113.1679 111.4495 112.7956 111.5896 111.2393\n\n\n\nTo access the latitude value\n\ndouble bracket notation [[ ]] and 2\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\nWith both longitude and latitude, use cbind() to combine both in the same object,\n\ncoords <- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n8.5.3.1 Plotting Queen contiguity based neighbours map\nwm_ q is weight matrix using queen method (88 rows of list of neighbours)\ncoords is an array of x,y coordinates of centroids for each of the 88 counties\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen's contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\nUse the plot() function\n\nThe shape of the markers: The plot markers are by default small, empty circles. These are also known as plot characters - denoted by pch. Pch values 0 to 25 are valid and give several different symbols on the graph. Pch 0 is for a square, 1 is for a circle, 3 is for a triangle, 4 is for a cross and so on.\nSize of the plot markers: The cex parameter can be set to 0.5 if we want the markers to be 50% smaller and 1.5 if wewant them to be 50% larger.\nColor of the plot markers: These colors can be selected from a list provided by R under the colors() function.\n\n\n\n\n8.5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border = 'lightgrey', main='Rooks contiguity')\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col =\"blue\")\n\n\n\n\n\n\n8.5.3.3 Plotting both Queen and Rook contiguity based neighbours maps side-by-side\npar(mfrow = c(1, 2)) arranges subsequent plots in a grid with one row and two columns\n\npar(mfrow=c(1,2))\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen's contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\",main=\"Rook's contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"blue\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#theories",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#theories",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "Theories",
    "text": "Theories\nSummary of deriving spatial weights matrix"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#getting-started",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#getting-started",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.2 Getting Started",
    "text": "9.2 Getting Started\n\n9.2.1 The analytical question\n\nIn spatial policy, local government/planners aims to ensure equal distribution of development in the province.\nwe should apply appropriate spatial statistical methods to discover if development are even distributed geographically in the province\nif answer is NO, we ask “is there sign of clustering?” (GLOBAL spatial autocorrelation)\nif YES, “Where are the clusters” (LOCAL spatial autocorrelation)\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China. (https://en.wikipedia.org/wiki/Hunan)\n\n\n\n\n\n9.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise:\n\nGeospatial data: Hunan province administrative boundary layer at county level in ESRI shapefile format\nAspatial data: Hunan_2012.csv containing local development indicators\n\n\n\n9.2.3 Setting the Analytical Tools\nPackages we need:\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#learning-outcome",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#learning-outcome",
    "title": "Hands-on Exercise 2.2: Global Measures of Spatial Autocorrelation",
    "section": "1.1 Learning Outcome",
    "text": "1.1 Learning Outcome"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#importing-geospatial-data",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#importing-geospatial-data",
    "title": "Hands-on Exercise 2.2: Global Measures of Spatial Autocorrelation",
    "section": "Importing Geospatial data",
    "text": "Importing Geospatial data"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#theories",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#theories",
    "title": "Hands-on Exercise 2.2: Global Measures of Spatial Autocorrelation",
    "section": "Theories",
    "text": "Theories"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_3.html#getting-started",
    "href": "Hands-on_Ex2/Hands-on_Ex2_3.html#getting-started",
    "title": "Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation",
    "section": "10.2 Getting Started",
    "text": "10.2 Getting Started\n\n10.2.1 The analytical question\n\nIn spatial policy, local government/planners aims to ensure equal distribution of development in the province.\nwe should apply appropriate spatial statistical methods to discover if development are even distributed geographically in the province\nif answer is NO, we ask \"is there sign of clustering?\" (GLOBAL spatial autocorrelation)\nif YES, \"Where are the clusters\" (LOCAL spatial autocorrelation)\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Provice, People Republic of China. (https://en.wikipedia.org/wiki/Hunan)\n\n\n10.2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nGeospatial data: Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nAspatial data: Hunan_2012.csv: This csv file contains selected Hunan's local development indicators in 2012.\n\n\n\n10.2.3 Setting the Analytical Toolls\nPackages that we will be using are:\n\nsf is use for importing and handling geospatial data in R,\ntidyverse is mainly use for wrangling attribute data in R,\nspdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\ntmap will be used to prepare cartographic quality chropleth map.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_3.html#learning-outcome",
    "href": "Hands-on_Ex2/Hands-on_Ex2_3.html#learning-outcome",
    "title": "Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation",
    "section": "1.1 Learning Outcome",
    "text": "1.1 Learning Outcome"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_3.html#importing-geospatial-data",
    "href": "Hands-on_Ex2/Hands-on_Ex2_3.html#importing-geospatial-data",
    "title": "Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation",
    "section": "Importing Geospatial data",
    "text": "Importing Geospatial data"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_3.html#theories",
    "href": "Hands-on_Ex2/Hands-on_Ex2_3.html#theories",
    "title": "Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation",
    "section": "Theories",
    "text": "Theories"
  },
  {
    "objectID": "In-class_Ex1/data/geospatial/MPSZ-2019/MPSZ-2019.html",
    "href": "In-class_Ex1/data/geospatial/MPSZ-2019/MPSZ-2019.html",
    "title": "NYX Geospatial App",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Ex1/In-class_Ex1.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The code chunk below loads the following packages:\n\ntmap: for thematic mapping\nsf: for geospatial data handling\ntidyverse: for non spatial data handling\n\n\npacman::p_load(sf, tmap, tidyverse, knitr)\n\n\n\nFirstly we will import the Passenger volume by Origin Destination Bus Stops dataset downloaded from the LTA Datamall by using the read_csv() of the readr package (to read text data).\n\nodbus_aug <- read_csv(\"data\\\\aspatial\\\\origin_destination_bus_202308.csv\")\n\nConverting character data type to factor data type.\n\nodbus_aug$ORIGIN_PT_CODE <- as.factor(odbus_aug$ORIGIN_PT_CODE)\nodbus_aug$DESTINATION_PT_CODE <- as.factor(odbus_aug$DESTINATION_PT_CODE)\n\nDerive a new field called TRIPS .\n22009: Boon Lay\n46009: Woodlands interchange\n75009: Tampines interchange\nBetter to have a map\n\norigtrip_7_9 <- odbus_aug %>% \n  filter(DAY_TYPE == 'WEEKDAY') %>% \n  filter(TIME_PER_HOUR >= 7 &\n           TIME_PER_HOUR <= 9) %>% \n  group_by(ORIGIN_PT_CODE) %>% \n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\norigtrip_7_9 %>% arrange(desc(TRIPS))\n\n# A tibble: 5,015 × 2\n   ORIGIN_PT_CODE  TRIPS\n   <fct>           <dbl>\n 1 22009          295128\n 2 46009          232902\n 3 75009          134781\n 4 52009          121422\n 5 55509          113434\n 6 24009          108437\n 7 65199          100791\n 8 59009           92333\n 9 84009           88092\n10 54261           86565\n# ℹ 5,005 more rows\n\n\n\n\n\nTwo geospatial data will be used in this exercise.\n\n\n\nbustop <- st_read(dsn=\"data\\\\geospatial\\\\BusStopLocation\\\\BusStopLocation_Jul2023\", layer = \"BusStop\") %>% \n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\In-class_Ex1\\data\\geospatial\\BusStopLocation\\BusStopLocation_Jul2023' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\nLoad the geospatial data of basemap from gov.sg , usually in WSG84 format\n\nmpsz <- st_read(dsn=\"data\\\\geospatial\\\\MPSZ-2019\", layer='MPSZ-2019')  %>% \n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\In-class_Ex1\\data\\geospatial\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class_Ex2/In-class_Ex2.html",
    "href": "In-class_Ex2/In-class_Ex2.html",
    "title": "In-class Exercise 2:",
    "section": "",
    "text": "#pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex3/In-class_Ex3.html",
    "href": "In-class_Ex3/In-class_Ex3.html",
    "title": "In-class Exercise 3:",
    "section": "",
    "text": "#pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex4/In-class_Ex4.html",
    "href": "In-class_Ex4/In-class_Ex4.html",
    "title": "In-class Exercise 4:",
    "section": "",
    "text": "#pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex5/In-class_Ex5.html",
    "href": "In-class_Ex5/In-class_Ex5.html",
    "title": "In-class Exercise 5:",
    "section": "",
    "text": "#pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624_AGA",
    "section": "",
    "text": "Welcome to my Applied Geospatial Analysis Website.\nI will be sharing my learning journey with you."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.6 Computing distance based neighbours",
    "text": "8.6 Computing distance based neighbours\n\nIn this section, we will derive distance-based weight matrices by using dnearneigh() of spdep package.\ndnearneigh(x, d1, d2, row.names = NULL, longlat = NULL, bounds=c(“GE”, “LE”),\n use_kd_tree=TRUE, symtest=FALSE, use_s2=packageVersion(“s2”) > “1.0.7”, k=200,\n dwithin=TRUE)\nidentifies neighbours using distance band with lower d1= and upper d2= bounds controlled by the bounds= argument\nIf unprojected coordinates are used (WSG84 geographic) and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\n8.6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. Class: ‘knn’. Output: NN of poly1 = poly3, NN of poly2 = poly 78 etc…\n\nstr(knearneigh(coords,\n           k=1))\n\nList of 5\n $ nn       : int [1:88, 1] 3 78 1 5 4 69 67 46 84 70 ...\n $ np       : int 88\n $ k        : num 1\n $ dimension: int 2\n $ x        : num [1:88, 1:2] 112 112 112 112 112 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:2] \"longitude\" \"latitude\"\n - attr(*, \"class\")= chr \"knn\"\n - attr(*, \"call\")= language knearneigh(x = coords, k = 1)\n\n#knearneigh(coords,k=1)['nn']  #<< shows matrix\n\nConvert the matrix knn object returned by knearneigh() into a neighbours list with a list of integer vectors containing neighbour region number ids by using knn2nb(). Class: nb\n\nknn2nb(knearneigh(coords))[1:5]\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 78\n\n[[3]]\n[1] 1\n\n[[4]]\n[1] 5\n\n[[5]]\n[1] 4\n\n\nReturn a list of the length (the distance to one’s nearest neighbour) of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km if in WSG84. Class: ‘nbdist’\n\nnbdists(knn2nb(knearneigh(coords, k=1)),\n        coords,\n        longlat = TRUE) [1:5]\n\n[[1]]\n[1] 25.53398\n\n[[2]]\n[1] 43.03114\n\n[[3]]\n[1] 25.53398\n\n[[4]]\n[1] 29.2848\n\n[[5]]\n[1] 29.2848\n\n\nRemove the list structure of the returned object by using unlist(). Class of k1dists: numeric.\nOutput: 25.53398 43.03114 25.53398 29.28480 29.28480 45.98097 58.52704 28.95985 34.45062 37.99885 44.49442 33.48816 35.98123\n\nk1 <- knn2nb(knearneigh(coords, k=1))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79. So using this as the upper threshold (62km) will help to ensure that all units (polygons) will have at least one neighbour.\n\n\n8.6.2 Computing fixed distance weight matrix\n(Earlier, we had used poly2nb(hunan, queen=TRUE/FALSE) to define neighbours using Queen or Rook method, resulting in wm_q and wm_r.)\n(We also have k1 of ‘nb’ class where each polygon has 1 nb. Additionally, we used summary(unlist(nbdists())) to calculate the distance between furthest neighbours.)\nNow, to define neighbours using a distance threshold, we use the dnearneigh() ,\n\nlonglat argument: TRUE if point coordinates are geographical longitude-latitude decimal degrees (WSG84)\nsome polygons have more than 1 nb, but all polygons have at least 1 nb here due to distance threshold.\n\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat=TRUE )\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAverage number of links is calculated by dividing the total number of links by the number of regions. On average, each region has approximately 3.68 neighboring regions. Class of wm_d62: ‘nb’\n\nclass(wm_d62)\n\n[1] \"nb\"\n\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\nThe column headers “1” means the count of counties that have 1 neighbor within the specified distance of 62km, “2” means the count of counties that have 2 neighbors, and so on.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\nTO find the number of connected components (aka see if there are any spatial units / regions without a neighbour)\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\nIn this connected component, there are 88 elements (spatial units)\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n8.6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nwm_d62 is the fixed distance weight matrix,\ncoords refers to long, lat coordinates for CG of each polygon\nk1 is the list of integer ID of the polygon which is the nearest neighbour to me. The topmost layer of the plot colours the nearest neighbour edge to red colour.\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08) \n\n\n\n\nThe red lines shows the links of 1st nearest neighbours and the black lines show the lines of neighbours within the cut-off distance of 62km.\nTo plot red and black side by side,\n\npar(mfrow = c(1, 2))\nplot(hunan$geometry, border=\"lightgrey\", main = 'Neighbours within 62 km')\nplot(wm_d62, coords, add=TRUE)\nplot(hunan$geometry, border=\"lightgrey\", main = 'Nearest Neighbour')\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08) \n\n\n\n\n\n\n\n8.6.3 Computing adaptive distance weight matrix\nUse this method if the dataset is highly skewed to fix the # of nbs.\nEarlier, we used k1 <- knn2nb(knearneigh(coords, k=1)) and wm_d62 <- dnearneigh(coords, 0, 62, longlat=TRUE ) to plot maps of nearest nb and nbs within 62km range.\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below. class of knn6: ‘nb’\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str(). Note that each spatial units has exactly 6 neighbours.\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\n8.6.3.1 Plotting distance based neighbours\n\nplot(st_geometry(hunan), border = 'lightgray')\nplot(knn6, coords, pch=18, cex=0.6, add= TRUE, col='red')"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#weights-based-on-inverse-distance-method",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#weights-based-on-inverse-distance-method",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.7 Weights based on Inverse Distance Method",
    "text": "8.7 Weights based on Inverse Distance Method\nIn this section, we will learn how to derive a spatial weight matrix based on Inversed Distance method. This will assign greater weightage to closer polygons, use this if we know that closer proximity will result in more spatial interaction.\nEarlier, we applied nbdists() nbdists(knn2nb(knearneigh(coords, k=1)), coords, longlat = TRUE) to compute the distance of one’s nearest neighbour.\nFirst, we will compute the distances between areas (defined using Queen contiguity method) by using nbdists() of spdep. Class of dist: nbdist\n\ndist <- nbdists(wm_q, coords, longlat=TRUE)\nhead(dist,3)\n\n[[1]]\n[1] 65.12941 25.53398 54.91802 35.61352 87.32760\n\n[[2]]\n[1] 65.12941 56.67944 51.92312 43.03114 58.16151\n\n[[3]]\n[1] 25.53398 35.43536 27.05778 71.64530\n\n\nNow compute the inverse distances for all polygons to their neighbours. Class of ids: matrix of list. ids is also glist (general weights for each nb).\n\nids <- lapply(dist, function(x) 1/(x))\nhead(ids,3)\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n\n\n8.7.1 Row-standardised weights matrix\nnb2listw(neighbours, glist=NULL, style=\"W\", zero.policy=NULL)\nArguments\n\n\n\n\n\n\n\nneighbours\nan object of class nb\n\n\n\n\nglist\nlist of general weights corresponding to neighbours\n\n\nstyle\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”\n\n\nzero.policy\ndefault NULL, use global option value; if FALSE stop with error for any empty neighbour sets, if TRUE permit the weights list to be formed with zero-length weights vectors\n\n\n\nDetails\nStarting from a binary neighbours list, in which regions are either listed as neighbours or are absent (thus not in the set of neighbours for some definition), the function adds a weights list with values given by the coding scheme style chosen.\nWeights to each neighboring polygon\n\neach neighboring polygon will be assigned equal weight (style=“W”) <- row standardised. This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values\ndrawback of this method is that polygon along the edge will base their lagged values on fewer polygons, thus over estimating the true nature of spatial autocorrelation in the data. Next time can consider other more robust options are available, notably style=“B” <- basic binary coding\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error. Class of rsmq_q = ‘listw’ and ‘nb’\n\n\nstyle = ‘W’style = ‘B’\n\n\n\n# wm_q is a matrix containing nb indexes\nrswm_q <- nb2listw(wm_q, style = 'W', zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\nnb2listw(wm_q, style = 'B', zero.policy = TRUE)$weights[1]\n\n[[1]]\n[1] 1 1 1 1 1\n\n\n\n\n\n\nclass(rswm_q)\n\n[1] \"listw\" \"nb\"   \n\n\nTo see the weight of the first polygon’s 5 neighbours type:\n\nrswm_q$weights[1]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nThe 5 neighbours are\n\nrswm_q$neighbours[1]\n\n[[1]]\n[1]  2  3  4 57 85\n\n\nExplanation of above: Each neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same queen’s method, we can also derive a (row standardised ?) inverse-distance weight matrix by using the code chunk below. Recall ids contains inverse-distances to neighbours, also our glist (general weights of neighbours) , originally from queens wm_q which is a neighbour structure. We will now use nb2listw() and wm_q and ids to create a spatial weights matrix. Class of rswm_ids is ‘listw’ and ‘nb’. It contains 3 lists, ‘style’ of class character ,‘neighbours’ of class nb, ‘weights’ of class nb\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style ='W', zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 40.39879 361.0957\n\n\nTo see the weights of the 1st polygon; it is actually the similar as ids, but not identical.\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.1367760 0.3488740 0.1622080 0.2501337 0.1020083\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.05894 0.13342 0.17603 0.19643 0.23961 1.00000 \n\n\nFinally, a comparison of the weights for polygon 1 across three spatial weights methods:\n\na <- unlist(rswm_q$weights[1])\nb <- unlist(nb2listw(wm_q, style = 'B', zero.policy = TRUE)$weights[1])\nc <- unlist(rswm_ids$weights[1])\n\nweights_comparison <- as.data.frame(cbind(a,b,c))\ncolnames(weights_comparison) <- c(\"row standardised\", \"binary\", 'row standardised inverse distance')\nweights_comparison\n\n  row standardised binary row standardised inverse distance\n1              0.2      1                         0.1367760\n2              0.2      1                         0.3488740\n3              0.2      1                         0.1622080\n4              0.2      1                         0.2501337\n5              0.2      1                         0.1020083"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "8.8 Application of Spatial Weight Matrix",
    "text": "8.8 Application of Spatial Weight Matrix\nIn this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n8.8.1 Spatial lag with row-standardized weights\n\ncompute the average neighbour GDPCC values for each polygon\ncommonly called spatially lagged values\ndoes not include itself\nRecalled in the previous section, we retrieved the GDPPC of these five countries (neighbours of poly1 using queen method) by using the code chunk below.\n\n\nx1 <- wm_q[[1]]\nhunan$GDPPC[c(x1)]\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nNow we compute the row-standardised lag variable using lag.listw() and rsqm_q (neighbour structure).\nIn the code below, use spatial weight matrix (equal weightage of 0.2 for poly1 etc.. ) by 0.2 * 20981 + 0.2 * 34592 + 0.2 * 24473 + 0.2 * 21311 + 0.2 * 22879 = 24847.20 for poly1 “Anxiang”\n22724.80 is the average GDPPC for poly2 based on equal weightage (0.2) of all its five neighbours . 24143.25 for poly3 based on equal weightage (0.25) based on four neighbours.\n\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\nFirst, create lag.list that contains two individual lists, namely NAME_3 column in hunan and the lag variable. Next, transform both lists into a dataframe. Rename the column headers. Perform a left join with hunan and lag.res will automatically use NAME_3 column as the join column.\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nstr(lag.list)\n\nList of 2\n $ : chr [1:88] \"Anxiang\" \"Hanshou\" \"Jinshi\" \"Li\" ...\n $ : num [1:88] 24847 22725 24143 27738 27270 ...\n\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nhead(as_tibble(hunan),3)\n\n# A tibble: 3 × 8\n  NAME_2   ID_3 NAME_3  ENGTYPE_3   County  GDPPC `lag GDPPC`\n  <chr>   <int> <chr>   <chr>       <chr>   <dbl>       <dbl>\n1 Changde 21098 Anxiang County      Anxiang 23667      24847.\n2 Changde 21100 Hanshou County      Hanshou 20981      22725.\n3 Changde 21101 Jinshi  County City Jinshi  34592      24143.\n# ℹ 1 more variable: geometry <POLYGON [°]>\n\n# head(hunan,3) %>%  kable()\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, 'GDPPC') +\n    tm_layout(main.title='No lag variable',\n              legend.height = 0.2,\n              legend.width=0.2)\nlag_gdppc <- qtm(hunan, 'lag GDPPC') +\n  tm_layout(main.title='With lag variable (Row-stand)',\n            legend.height = 0.2,\n            legend.width=0.4)\n\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe chart on the left plots the original GDPPC values of respective spatial units. The chart on the right plots the average GDPPC values of all spatial units that shares a boundary (Queen) for a particular spatial unit. Does not include diagonal (own’s) GDPPC value.\n\n\nCompute lag variable using rswm_ids (inverse-distance method)\n\nlag.list.2 <- list(hunan$NAME_3, lag.listw(rswm_ids, hunan$GDPPC))\nstr(lag.list.2)\n\nList of 2\n $ : chr [1:88] \"Anxiang\" \"Hanshou\" \"Jinshi\" \"Li\" ...\n $ : num [1:88] 26572 22568 24356 28108 28265 ...\n\nlag.res.2 <- as.data.frame(lag.list.2)\ncolnames(lag.res.2) <- c(\"NAME_3\", \"lag GDPPC ID\")\nhunan <- left_join(hunan,lag.res.2)\n\nhead(as_tibble(hunan),3)\n\n# A tibble: 3 × 9\n  NAME_2   ID_3 NAME_3  ENGTYPE_3   County  GDPPC `lag GDPPC` `lag GDPPC ID`\n  <chr>   <int> <chr>   <chr>       <chr>   <dbl>       <dbl>          <dbl>\n1 Changde 21098 Anxiang County      Anxiang 23667      24847.         26572.\n2 Changde 21100 Hanshou County      Hanshou 20981      22725.         22568.\n3 Changde 21101 Jinshi  County City Jinshi  34592      24143.         24356.\n# ℹ 1 more variable: geometry <POLYGON [°]>\n\nlag_gdppc_id <- qtm(hunan, 'lag GDPPC ID') +\n  tm_layout(main.title='With lag variable (Inv_dist)',\n            legend.height = 0.2,\n            legend.width=0.4)\n\ntmap_arrange(lag_gdppc, lag_gdppc_id, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nLag variable using Queen’s contiguity (Row standardised weight matrix)\nThe lag variable represents the spatial AVERAGE of GDPPC for neighbouring areas based on Queen contiguity.\nLag variable using Inverse-Distance Weight matrix\nThe lag variable is calculated as a WEIGHTED AVERAGE of GDPPC. Further neighbours are penalised (assign lesser weights) when we use inverse-distance.\n\n\n\n\n8.8.2 Spatial lag as a sum of neighboring values\nPart 1: Obtain binary weights matrix called 'b_weights' (glist):\nwm_q (aka neighbour list) is a 'nb' class containing neighbour IDs for each polygon. E.g. Neighbours list of the first three polygons:\n\n\n[[1]]\n[1]  2  3  4 57 85\n\n[[2]]\n[1]  1 57 58 78 85\n\n[[3]]\n[1]  1  4  5 85\n\n\nTo create a binary list, we will now apply lambda function of 0*neighbour ID + 1 ; so that if there is a neighbour, the value is 1. Class of b_weights is a matrix with lists of 1 .\nSimilar to ids earlier, b_weights is the glist (general weights corresponding to neighbours). We need the neighbour structure wm_q and glist to convert to spatial weights matrix using nb2listw().\n\nb_weights <- lapply(wm_q, function(x) 0*x+1)\nclass(b_weights)\n\n[1] \"list\"\n\nb_weights[1:3]\n\n[[1]]\n[1] 1 1 1 1 1\n\n[[2]]\n[1] 1 1 1 1 1\n\n[[3]]\n[1] 1 1 1 1\n\n\nPart 2: Create the spatial weights matrix using nb2listw() , wm_q (neighbour structure) and b_weights (glist)\n\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nSneakpeak at b_weights2\n\nb_weights2$weights[1:3]\n\n[[1]]\n[1] 1 1 1 1 1\n\n[[2]]\n[1] 1 1 1 1 1\n\n[[3]]\n[1] 1 1 1 1\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC. Since the weights are all ‘1’s, we will be summing all our neighbours’ GDPPC.\nlag_sum contains two lists, namely NAME_3 and lag_sum GDPPC. Combine both lists into a df. Rename the df column headers.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nstr(lag_sum)\n\nList of 2\n $ : chr [1:88] \"Anxiang\" \"Hanshou\" \"Jinshi\" \"Li\" ...\n $ : num [1:88] 124236 113624 96573 110950 109081 ...\n\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c('NAME_3', 'lag_sum GDPPC')\n\nNext, append lag.res to hunan sf dataframe\n\nhunan <- left_join(hunan, lag.res)\n\nPlot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, 'GDPPC') +\n    tm_layout(main.title='No lag variable',\n              legend.height = 0.2,\n              legend.width=0.2)\n\nlag_sum_gdppc <- qtm(hunan, 'lag_sum GDPPC') +\n  tm_layout(main.title = 'spatial lag as lag sum of nb values',\n            legend.height = 0.2,\n            legend.width=0.2)\n\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe lag variable created by summing up neighbours’ GDPPC look more alike the lag variable created using inverse-distance weights matrix.\n\n\n\n\n8.8.3 Spatial window average\n\nmust use row-standardized weights\nsimilar to 8.8.1 but only difference is that it includes the diagonal element;\nTo include diagonal in R, we need to go back to the neighbors structure wm_q and add the diagonal element before assigning weights.\n\n\n# weight matrix queen self\nwm_qs <- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nwm_qs[1:3]\n\n[[1]]\n[1]  1  2  3  4 57 85\n\n[[2]]\n[1]  1  2 57 58 78 85\n\n[[3]]\n[1]  1  3  4  5 85\n\n\nWe can see that polygon 1 has its diagonal (1) inside and polygon 2 has its diagonal (2) inside.We can see that polygon 1 has its diagonal (1) inside and polygon 2 has its diagonal (2) inside.\nAs expected, the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909.\nNow, proceed to create the spatial weights matrix that includes self:\nDefault style is ‘W’ - row standardised.\n\nwm_qs <- nb2listw(wm_qs, style ='W', zero.policy = TRUE)\nwm_qs$weights[1:3]\n\n[[1]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[2]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[3]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nNow, create lag variable using spatial weights matrix wm_qs and hunan$GDPCC variable:\n\nlag_w_ave_gdppc <- lag.listw(wm_qs,\n                             hunan$GDPPC)\nlag_w_ave_gdppc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nAppend lag_w_ave_gdppc to the hunan dataframe by using the series of steps below:\n\nlag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nstr(lag.list.wm_qs)\n\nList of 2\n $ : chr [1:88] \"Anxiang\" \"Hanshou\" \"Jinshi\" \"Li\" ...\n $ : num [1:88] 24651 22434 26233 27085 26927 ...\n\nlag_wm_qs.res <- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) <- c('NAME_3', 'lag_window_avg GDPPC')\n\nhunan <- left_join(hunan, lag_wm_qs.res)\n\nhunan %>% \n  select('County', 'lag GDPPC', 'lag_window_avg GDPPC') %>% \n  head() %>% \n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\n\n\n#as_tibble(hunan)  #<< will isolate the geometry part\n\nUse dtm() to plot ‘lag GDPPC’ and ‘lag_window_avg GDPPC’ side-by-side\n\nW_avg_gdppc <- qtm(hunan, 'lag_window_avg GDPPC') +\n  tm_layout(main.title='With lag_sum variable',\n            legend.height = 0.2,\n            legend.width=0.4)\n\ntmap_arrange(lag_gdppc, W_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBoth charts use row-standardised spatial weights matrix.\nDifference between charts is that left does not include self’s GDPPC but the right includes self’s GDPPC.\n\n\n\n\n8.8.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights. (similar to 8.8.2 but including self)\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs <- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary general weights to the neighbour structure that includes the diagonal element.\n\nb_weights <- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1:3]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n[[2]]\n[1] 1 1 1 1 1 1\n\n[[3]]\n[1] 1 1 1 1 1\n\n\nEach spatial unit has one more element, that is itself.\nAgain, we use nb2listw() and wm_qs (nb structure) and b_weights (glist) to create spatial weights matrix b_weights\n\nb_weights2 <- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nCompute the window sum lag variable using lag.listw(), b_weights2 (spatial weights matrix) and hunan$GDPCC (variable). The below also appends the window sum lag variable to hunan df.\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nstr(w_sum_gdppc)\n\nList of 2\n $ : chr [1:88] \"Anxiang\" \"Hanshou\" \"Jinshi\" \"Li\" ...\n $ : num [1:88] 147903 134605 131165 135423 134635 ...\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\nhunan %>%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %>%\n  head() %>% \n  kable()\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nW_sum_gdppc <- qtm(hunan, 'w_sum GDPPC') +\n  tm_layout(main.title='With lag_win_sum variable',\n            legend.height = 0.2,\n            legend.width=0.4)\n\ntmap_arrange(lag_sum_gdppc, W_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBoth charts do not use row-standardised spatial matrix, instead they use binary ‘1’ because of the need to sum up the GDPPC values. Difference is that left does not include self but right includes self.\n\n\n\n#| eval: false\n#| echo: false\n#| fig-width: 14\n#| fig-asp: 0.68\n#| code-fold: True"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_1.html#summaries",
    "href": "Hands-on_Ex2/Hands-on_Ex2_1.html#summaries",
    "title": "Hands-on Exercise 2.1: Spatial Weights and Applications",
    "section": "Summaries",
    "text": "Summaries\nSummary of deriving spatial weights matrix\n\nSummary of deriving lag variables"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will learn to\n\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#getting-the-data-into-r-environment",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.3 Getting the Data Into R Environment",
    "text": "9.3 Getting the Data Into R Environment\nThe geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n9.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\nhunan is in WSG84 geographical system.\n\nhunan <- st_read(dsn='data/geospatial',\n                 layer='Hunan')\n\nReading layer `Hunan' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n#st_crs(hunan)\nhead(hunan,3)\n\nSimple feature collection with 3 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 111.7027 ymin: 28.61762 xmax: 112.3013 ymax: 29.77344\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3 Shape_Leng Shape_Area  County\n1 Changde 21098 Anxiang      County   1.869074 0.10056190 Anxiang\n2 Changde 21100 Hanshou      County   2.360691 0.19978745 Hanshou\n3 Changde 21101  Jinshi County City   1.425620 0.05302413  Jinshi\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n\n\n\n\n9.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 <- read_csv('data/aspatial/Hunan_2012.csv')\nhead(hunan2012,3)\n\n# A tibble: 3 × 29\n  County  City  avg_wage deposite   FAI Gov_Rev Gov_Exp    GDP GDPPC   GIO  Loan\n  <chr>   <chr>    <dbl>    <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 Anhua   Yiya…    30544   10967  6832.    457.   2703  13225  14567 9277. 3955.\n2 Anren   Chen…    28058    4599. 6386.    221.   1455.  4941. 12761 4189. 2555.\n3 Anxiang Chan…    31935    5517. 3541     244.   1780. 12482  23667 5109. 2807.\n# ℹ 18 more variables: NIPCR <dbl>, Bed <dbl>, Emp <dbl>, EmpR <dbl>,\n#   EmpRT <dbl>, Pri_Stu <dbl>, Sec_Stu <dbl>, Household <dbl>,\n#   Household_R <dbl>, NOIP <dbl>, Pop_R <dbl>, RSCG <dbl>, Pop_T <dbl>,\n#   Agri <dbl>, Service <dbl>, Disp_Inc <dbl>, RORP <dbl>, ROREmp <dbl>\n\n\n\n\n9.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame (geospatial) with the attribute fields of hunan2012 dataframe (aspatial) . This is performed by using left_join() of dplyr package. Since the join columns are not specified, identical columns names (‘County’) form both dataset will be used for the join.\nColumn 7 and 15 are the ‘County’ and ‘GDPPC’ columns respectively.\n\nhunan <- left_join(hunan, hunan2012) %>% \n  select(1:4, 7,15)\nhead(hunan,3)\n\nSimple feature collection with 3 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 111.7027 ymin: 28.61762 xmax: 112.3013 ymax: 29.77344\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667\n2 Changde 21100 Hanshou      County Hanshou 20981\n3 Changde 21101  Jinshi County City  Jinshi 34592\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n\n\n\n\n9.3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\ntm_fill() ’s n refer to the number of equal intervals\n\n\nequal <- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n=5,\n          style='equal') +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = 'Equal interval classification',\n            main.title.size=1.5,\n            legend.height = 0.25,\n            legend.width = 0.25)\n\nquantile <- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n=5,\n          style='quantile') +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = 'Equal quantile classification',\n            main.title.size=1.5,\n            legend.height = 0.25,\n            legend.width = 0.25)\n\ntmap_arrange(equal, quantile, asp =1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#global-spatial-autocorrelation",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#global-spatial-autocorrelation",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.4 Global Spatial Autocorrelation",
    "text": "9.4 Global Spatial Autocorrelation\nIn this section, we will\n\ncompute global spatial autocorrelation statistics\nperform spatial complete randomness test for global spatial autocorrelation (test for significance).\n\n\n9.4.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function will\n\nbuild a neighbours list based on regions with contiguous boundaries.\nif ‘queen’ argument is TRUE: spatial units are considered neighbours if they share a common point. A list of first order neighbours using the Queen criteria will be returned.\nif ‘queen’ argument is FALSE: spatial unit are considered neighbours if they share a least two common points.\n\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan,\n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nSneakpeak at the neighbours’ list of the first three polygons.\n\nwm_q[1:3]\n\n[[1]]\n[1]  2  3  4 57 85\n\n[[2]]\n[1]  1 57 58 78 85\n\n[[3]]\n[1]  1  4  5 85\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n9.4.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q <- nb2listw(wm_q,\n                   style='W',\n                   zero.policy=TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nSneak peak at the neighbour weights of the first three polygons\n\nrswm_q$weights[1:3]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[2]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n[[3]]\n[1] 0.25 0.25 0.25 0.25\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\n\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\nattributes(rswm_q)\n\n$names\n[1] \"style\"      \"neighbours\" \"weights\"   \n\n$class\n[1] \"listw\" \"nb\"   \n\n$region.id\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\" \"26\" \"27\" \"28\" \"29\" \"30\"\n[31] \"31\" \"32\" \"33\" \"34\" \"35\" \"36\" \"37\" \"38\" \"39\" \"40\" \"41\" \"42\" \"43\" \"44\" \"45\"\n[46] \"46\" \"47\" \"48\" \"49\" \"50\" \"51\" \"52\" \"53\" \"54\" \"55\" \"56\" \"57\" \"58\" \"59\" \"60\"\n[61] \"61\" \"62\" \"63\" \"64\" \"65\" \"66\" \"67\" \"68\" \"69\" \"70\" \"71\" \"72\" \"73\" \"74\" \"75\"\n[76] \"76\" \"77\" \"78\" \"79\" \"80\" \"81\" \"82\" \"83\" \"84\" \"85\" \"86\" \"87\" \"88\"\n\n$call\nnb2listw(neighbours = wm_q, style = \"W\", zero.policy = TRUE)\n\nmethods(class=class(rswm_q))\n\n[1] coerce      initialize  lag         plot        print       show       \n[7] slotsFromS3 subset      summary    \nsee '?methods' for accessing help and source code\n\n\n\n\n9.4.3 Global Spatial Autocorrelation: Moran’s I\nIn this section, we will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n\n9.4.4 Moran’s I test\nGlobal spatial association assesses the overall spatial pattern of a variable across the entire study area. It provides a single value or metric that summarizes the extent to which similar values cluster together or are dispersed across the entire geographic space.\nThe Moran’s I assumes data follows a normal distribution and are randomised.\nMoran’s I values range from -1 to 1 while Geary’s C ranges from 0 to 2. The chart below summarises our lecture material.\n\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep. It takes in the main arguments:\n\nvariable\nlistw , our spatial weights matrix that defines the neighbourhood and relationship between them.\n\n\nmoran.test(hunan$GDPPC,\n           listw = rswm_q,\n           zero.policy=TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nThe null hypothesis: Observed spatial patterns of values is equally likely as any random spatial pattern.\nSince the p-value is less than 0.05 and Moran I statistic is greater than 1, we can reject the null hypothesis and conclude that similar values tend to cluster together in our area of study.\n\n\n9.4.4.1 Computing Monte Carlo Moran’s I\nIn the event we are unsure whether the data follows a normal distribution and are randomised, we can use the Monte Carlo Simulation to simulate Moran’s I n times under the assumption of no spatial pattern (shuffle/permutate the variable across all spatial units). This creates a baseline to compare with the observed Moran’s I value from dataset.\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm = moran.mc(hunan$GDPPC,\n                 listw=rswm_q,\n                 nsim=999,\n                 zero.policy=TRUE,\n                 na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nSince the p-value is less than 0.05 and Moran I statistic is greater than 1, we can reject the null hypothesis and conclude that similar values tend to cluster together in our area of study.\n\n\n9.4.4.2 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\nGet the mean of simulated moran’s I values. The ‘res’ column contains the simulated moran’s i values.\n\nmean(bperm$res[1:999]) \n\n[1] -0.01504572\n\n\nGet the variance\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\nSummary statistics\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nPlotting\n\nggplot2Base Graph\n\n\nWe will use ggplot2 to create the histogram instead of base r.\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(ggthemes)\n\nbperm_df <- as.data.frame(bperm$res)\ncolnames(bperm_df) <- c('res')\n\n#q <- quantile(bperm_df$res[1:999], probs = c(0.25, 0.5, 0.75))\nmean <- mean(bperm_df$res[1:999])\nmean\n\n\n[1] -0.01504572\n\n\nShow the code\nggplot(data=bperm_df,\n       aes(x=res)) +\n  geom_histogram(bins=20,\n                 color='grey25',\n                 fill='grey90',size=0.8) +\n  #geom_vline(xintercept = q[2], linetype='dotted', size = 0.8, color='blue') +\n  #geom_vline(xintercept = q[3], linetype='dotted', size = 0.8) +\n  geom_vline(xintercept = mean, linetype='dotted', size = 0.8, color='red') +\n  #annotate('text' , x= -0.055, y=180, label='50th \\npercentile', size = 5, color='blue') +\n  #annotate('text' , x= 0.06, y=180, label='75th \\npercentile', size = 5) +\n  annotate('text' , x= 0.015, y=180, label='mean', size = 5, color='red') +\n  labs(y= 'Frequency', x=\"Moran's I values\") +\n  theme_economist() +\n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9)) +\n  ggtitle(\"Histogram of Simulated Moran's I\")\n\n\n\n\n\n\n\n\nhist(bperm$res,\n     freq=TRUE,\n     breaks=20,\n     xlab=\"Simulated Moran's I\",\n     main = paste(\"Histogram of Simulated Moran I\"))\nabline(v=0,\n       col='red')\n\n\n\n\n\n\n\n\n\n\n9.4.5 Global Spatial Autocorrelation: Geary’s\nIn this section, we will learn how to perform Geary’s c statistics testing by using appropriate functions of spdep package.\n\n9.4.5.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nThe null hypothesis: Observed spatial patterns of values is equally likely as any random spatial pattern.\nSince the p-value is less than 0.05 and Geary’s C statistic is greater 0 and less than 1, we can reject the null hypothesis and conclude that similar values tend to cluster together in our area of study.\n\n\n\n9.4.5.2 Computing Monte Carlo Geary’s C\nIn the event we are unsure whether the data follows a normal distribution and are randomised, the code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nSince the p-value is less than 0.05 and Geary’s C statistic is greater 0 and less than 1, we can reject the null hypothesis and conclude that similar values tend to cluster together in our area of study.\n\n\n9.4.5.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\nGet the mean of simulated Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\nGet the variance\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\nSummary statistics\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nPlot the histogram using ggplot2\n\n\nShow the code\nbperm_df <- as.data.frame(bperm$res)\ncolnames(bperm_df) <- c('res')\n\n#q <- quantile(bperm_df$res[1:999], probs = c(0.25, 0.5, 0.75))\nmean <- mean(bperm_df$res[1:999])\nmean\n\n\n[1] 1.004402\n\n\nShow the code\nggplot(data=bperm_df,\n       aes(x=res)) +\n  geom_histogram(bins=20,\n                 color='grey25',\n                 fill='grey90',size=0.8) +\n  geom_vline(xintercept = mean, linetype='dotted', size = 0.8, color='red') +\n  annotate('text' , x= 1.05, y=180, label='mean', size = 5, color='red') +\n  labs(y= 'Frequency', x=\"Geary's C values\") +\n  theme_economist() +\n  theme(axis.title.y=element_text(angle = 0,\n                                  vjust=0.9)) +\n  ggtitle(\"Histogram of Simulated Geary's C\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#summaries",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#summaries",
    "title": "Hands-on Exercise 2.2: Global Measures of Spatial Autocorrelation",
    "section": "Summaries",
    "text": "Summaries"
  },
  {
    "objectID": "Take-home_Ex1/data/hexagon/hexagon.html",
    "href": "Take-home_Ex1/data/hexagon/hexagon.html",
    "title": "NYX Geospatial App",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n                 +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 0 0     false"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#getting-started",
    "href": "Take-home_Ex1/Take-home_Ex1.html#getting-started",
    "title": "Take-home_Ex1: Geospatial Analytics for Public Good",
    "section": "Getting Started",
    "text": "Getting Started\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#learning-outcome",
    "href": "Take-home_Ex1/Take-home_Ex1.html#learning-outcome",
    "title": "Take-home_Ex1: Geospatial Analytics for Public Good",
    "section": "1.1 Learning Outcome",
    "text": "1.1 Learning Outcome"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#importing-geospatial-data",
    "href": "Take-home_Ex1/Take-home_Ex1.html#importing-geospatial-data",
    "title": "Take-home_Ex1: Geospatial Analytics for Public Good",
    "section": "Importing Geospatial data",
    "text": "Importing Geospatial data"
  },
  {
    "objectID": "Take-home_Ex1/Take-home_Ex1.html#theories",
    "href": "Take-home_Ex1/Take-home_Ex1.html#theories",
    "title": "Take-home_Ex1: Geospatial Analytics for Public Good",
    "section": "Theories",
    "text": "Theories"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#spatial-correlogram",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#spatial-correlogram",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "9.5 Spatial Correlogram",
    "text": "9.5 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n9.5.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\nArguments:\n\n‘order’ refers to number of layers away from each polygon using contiguity method. We want to check how the Moran’s I values changes (and its statistical significance changes) as the neighbours get further and further away.\n‘method’: ‘corr’ for correlation, ‘I’ for Moran’s I and ‘C’ for Gerary’s C.\n\nUnderstanding the plot\nY-Axis: The y-axis typically represents the Moran’s I coefficient, which quantifies spatial autocorrelation. Above zero, similar values cluster. Below zero, dissimilar values cluster.\nX-Axis: The x-axis represents spatial distance lags. Each point on the correlogram corresponds to a specific distance lag (e.g., distance between observations). The points are usually organized in bins or distance classes.\nBars or Lines: Bars or lines connect the Moran’s I values at different distance lags, forming a pattern that shows how spatial autocorrelation changes with distance.\nUsefulness of Moran’s I Correlogram\nDetecting Spatial Patterns: A Moran’s I correlogram provides insights into the presence and structure of spatial patterns in our data. It helps identify at what distances spatial autocorrelation is significant.\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe see that with the exception of Lag 4, the rest of the results are statistically significant at the 95% level of confidence.\nAs we consider order lag from 1 to 3, there is significant positive autocorrelation (similar values cluster) and we note the Moran’s I values decreases as order increases. For order 5 and 6, there is significant negative autocorrelation (dissimilar values cluster)\nPossible reason for the change of polarity:\nLocal clusters could dominate at smaller distances while at larger distances, can detect dispersion more.\n9.5.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n0< Geary C < 1 : similar values cluster\n1 < Geary C < 2: dissimilar values cluster\nNow examine the full report to check which values are significant.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe results of Geary’s C statistics test is similar to Moran’s I.\nAll lag orders except Lag order of 3, 4 and 6 are statistically significant at 95% confidence level.\nLag order 1 and 2: clustering of similar values, order 2 is less clustered than order 1. (Moran’s I and Geary’s C are inversely related.)\nLag order 5: clustering of dissimilar values."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#cluster-and-outlier-analysis",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "10.6 Cluster and Outlier Analysis",
    "text": "10.6 Cluster and Outlier Analysis\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance if we are studying cancer rates among census tracts in a given city local clusters in the rates mean that there are localised areas that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, we will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster (HH or LL) and/or outlier (HL, LH) from GDP per capita 2012 of Hunan Province, PRC.\n\n10.6.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values (variable) and a listw object (spatial weights matrix) providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(z != E(Ii)): the p-value of local moran statistic\n\nNote there is no County’s name in the output above.\nWe must first create a dataframe that appends the County’s name to its local moran (li) values.\n\nFips is an object of integer class. It contains the row ids if rows are to be arranged in alphabetical order.\nlocalMI[Fips,] would arrange the rows of localMI in alphabetical order of its countys’ name, retaining all the columns.\nThe row names would take the countys’ name.\n\n\ndata.frame(\n  localMI[fips,],\n  row.names=hunan$County[fips]) %>% \n  head()\n\n                     Ii          E.Ii       Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua     -2.249264e-02 -5.004845e-03 5.823550e-02 -0.07246715      0.9422301\nAnren     -3.993226e-01 -7.011066e-03 7.034768e-02 -1.47912938      0.1391057\nAnxiang   -1.468468e-03 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\nBaojing    3.473702e-01 -5.008916e-03 8.363556e-02  1.21846947      0.2230456\nChaling    2.055902e-02 -9.681197e-04 2.771090e-02  0.12931859      0.8971056\nChangning -2.986822e-05 -9.001050e-09 1.510502e-07 -0.07682771      0.9387606\n\n\nThe code chunk below list the content of the local Moran matrix derived by using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]))\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n10.6.1.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\nThe Pr.z….E.Ii.. containing p-value of the local moran I is renamed to PR.Ii\n\nhunan.localMI <- cbind(hunan,localMI) %>% \n    rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n10.6.1.2 Mapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chunks below. For paletter colours, refer to colorbrewers link.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col='Ii',\n          style = 'pretty',\n          #palette = 'RdBu', # << refer to colourbrewer\n          title = 'Local Moran statistics') +\n  tm_borders(alpha= 0.5) + \n  tm_layout(main.title = \"Local Moran's I\",\n            legend.width= 0.25,\n            legend.height = 0.25)\n\n\n\n\n\n\n10.6.1.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\nVarious p valuesp values at 95% confidence level\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Local Moran's I p-values\",\n            legend.width= 0.25,\n            legend.height = 0.25)\n\n\n\n\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.05, Inf),\n          palette = c('lightblue', 'grey'), \n          title = \"Local Moran's I p-values\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Significant Local Moran's I \\np-values at 95% Confidence level\",\n            main.title.size = 1,\n            legend.width = 0.25,\n            legend.height = 0.25)\n\n\n\n\n\n\n\n\n\n10.6.1.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col='Ii',\n          style = 'pretty',\n          #palette = 'RdBu', # << reger to colourbrewer\n          title = 'Local Moran statistics') +\n  tm_borders(alpha= 0.5) + \n  tm_layout(main.title = \"Local Moran's I\",\n            legend.width= 0.25,\n            legend.height = 0.25)\n\npvalue.map <-tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks = c(-Inf, 0.05, Inf),\n          palette = c('lightblue', 'grey'), \n          title = \"Local Moran's I p-values\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Significant Local Moran's I \\np-values at 95% Confidence level\",\n            main.title.size = 1,\n            legend.width = 0.25,\n            legend.height = 0.25)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1,ncol=2)\n\n\n\n\n\nFor the choropleth chart on the left, dark green represents clustering of similar values (HH or LL, to be determine by Moran scatterplot or LISAmap) while orange represents outlier regions (LH or HL). THe chart on the right would show us the significant clusters or outliers."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_3.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2_3.html",
    "title": "Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, wewill learn how to compute Global and Local Measure of Spatial Autocorrelation (GLSA) by using spdep package. By the end to this hands-on exercise, we will be able to:\n\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\ncompute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions spdep package;\ncompute Getis-Ord's Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of spdep package; and\nto visualise the analysis output by using tmap package."
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_3.html#section",
    "href": "Hands-on_Ex2/Hands-on_Ex2_3.html#section",
    "title": "Hands-on Exercise 2.3:Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "10.3 Getting the Data Into R Environment\nThe geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n10.3.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\nhunan is in WSG84 geographical system.\n\nhunan <- st_read(dsn='data/geospatial',\n                 layer='Hunan')\n\nReading layer `Hunan' from data source \n  `C:\\yixin-neo\\ISSS624_AGA\\Hands-on_Ex2\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n10.3.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R data frame class.\n\nhunan2012 <- read_csv('data/aspatial/Hunan_2012.csv')\nhead(hunan2012,3)\n\n# A tibble: 3 × 29\n  County  City  avg_wage deposite   FAI Gov_Rev Gov_Exp    GDP GDPPC   GIO  Loan\n  <chr>   <chr>    <dbl>    <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 Anhua   Yiya…    30544   10967  6832.    457.   2703  13225  14567 9277. 3955.\n2 Anren   Chen…    28058    4599. 6386.    221.   1455.  4941. 12761 4189. 2555.\n3 Anxiang Chan…    31935    5517. 3541     244.   1780. 12482  23667 5109. 2807.\n# ℹ 18 more variables: NIPCR <dbl>, Bed <dbl>, Emp <dbl>, EmpR <dbl>,\n#   EmpRT <dbl>, Pri_Stu <dbl>, Sec_Stu <dbl>, Household <dbl>,\n#   Household_R <dbl>, NOIP <dbl>, Pop_R <dbl>, RSCG <dbl>, Pop_T <dbl>,\n#   Agri <dbl>, Service <dbl>, Disp_Inc <dbl>, RORP <dbl>, ROREmp <dbl>\n\n\n\n\n10.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan's SpatialPolygonsDataFrame (geospatial) with the attribute fields of hunan2012 dataframe (aspatial) . This is performed by using left_join() of dplyr package. Since the join columns are not specified, identical columns names ('County') form both dataset will be used for the join.\nColumn 7 and 15 are the 'County' and 'GDPPC' columns respectively.\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\n\n\n10.3.4 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\ntm_fill() 's n refer to the number of equal intervals\n\n\nequal <- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n=5,\n          style='equal') +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = 'Equal interval classification',\n            main.title.size=1.5,\n            legend.height = 0.25,\n            legend.width = 0.25)\n\nquantile <- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n=5,\n          style='quantile') +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = 'Equal quantile classification',\n            main.title.size=1.5,\n            legend.height = 0.25,\n            legend.width = 0.25)\n\ntmap_arrange(equal, quantile, asp =1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2_2.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex2/Hands-on_Ex2_2.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 2.2 and 2.3: Global and Local Measures of Spatial Autocorrelation",
    "section": "10.7 Creating a LISA Cluster Map",
    "text": "10.7 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n10.7.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci <- moran.plot(hunan$GDPPC,\n                  listw = rswm_q,\n                  labels = as.character(hunan$County),\n                  xlab = 'GDPPC 2012',\n                  ylab = 'Spatially lag GDPPC 2012')\n\n\n\n\n\nThe x -axis shows the original variable value at a particular spatial unit and the y-axis is the (weighted or without) average of the neighbouring variable values. The neighbour definition and relationship is embedded in the ‘listw’ argument where it could be\n\nspatial lag with row-standardised weights\nspatial lag as sum of neighbours values (binary)\nspatial window average (self-included)\nspatial window sum (self-included and binary)\ninverse-distance\n\nNotice that the plot is split in 4 quadrants.\n\nClusters and + spatial autocorrelation: The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\nCluster and + spatial autocorrelation: Bottom left are the Low-low.\nOutlier and - spatial autocorrelation: Top left contains spatial units with low GDPPC and surrounded by higher values.\nOutlier and - spatial autocorrelation: Bottom right contains spatial units with higher GDPPC and surrounded by relatively lower values.\n\n\n\n\n10.7.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\nhunan$GDPPC will have a mean of 0 and a standard deviation of 1.\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into our hunan dataframe\nWithout setting as vector, scale(hunan$GDPPC) is a matrix array.\nNow, plot the Moran scatterplot again by using the code chunk below.\n\nnci2 <- moran.plot(hunan$Z.GDPPC,\n                  listw = rswm_q,\n                  labels = as.character(hunan$County),\n                  xlab = 'GDPPC 2012',\n                  ylab = 'Spatially lag z-GDPPC 2012')\n\n\n\n\n\nWe notice that both axes are standardised with mean =0 and sd of 1.\n\n10.7.3 Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nThe code initializes a numeric vector named quadrant with a length equal to the number of rows in the localMI data frame. The vector is initially filled with NA.\n\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derive the spatially lagged variable of interest (i.e. GDPPC) using lag.listw() from the spdep package and centers the spatially lagged variable around its mean via subtraction.\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nclass(DV)\n\n[1] \"numeric\"\n\n\nRetrieve the first column (li aka Moran’s I values) from the localMI matrix and centered around its mean via subtraction.\n\n#colnames(localMI)\nLM_I <- localMI[,1] - mean(localMI[,1])\nclass(LM_I)\n\n[1] \"numeric\"\n\n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif <- 0.05\n\nThese four command lines define the (1) low-low, (2) low-high , (3) high-low and (4) high-high categories. Comparing the local Moran’s I values with its lag-variable values.\n\nquadrant[DV <0 & LM_I>0] <- 1 # LL\nquadrant[DV >0 & LM_I<0] <- 2 # LH\nquadrant[DV <0 & LM_I<0] <- 3 # HL\nquadrant[DV >0 & LM_I>0] <- 4 # HH\n\n\nLM_I > 0 : cluster of similar values.\n(1) When DV < 0 and LM_I > 0, low values of spatial lag variables cluster together with low non-lag variable. Thus Low-low.\n(4) When DV > 0 and LM_I > 0, high values of spatial lag variables cluster together with high non-lag variable. Thus high-high.\nLM_I <0 : cluster of dissimilar values.\n(2) When DV > 0 and LM < 0, high values of spatial lag variables are among low non-lag variable, thus low-high. (see moran scatterplot’s Y axis)\n(3) When DV < 0 and LM_I < 0 , low values of spatial lag variables are among the high non-lag variable, thus high-low.\n\n\nquadrant\n\n [1] 2 3 3 2 2 3 4 4 4 2 2 3 2 2 2 4 3 3 2 3 3 2 3 3 3 3 3 3 1 3 1 3 3 3 3 3 1 3\n[39] 1 1 3 1 1 1 3 4 2 1 3 3 3 3 1 3 1 2 2 2 3 3 3 3 2 3 2 4 2 4 3 3 4 2 2 4 3 2\n[77] 3 2 1 2 3 3 2 4 3 2 3 3\n\n\nLastly, places non-significant Moran in the category 0. The fifth column of the localMI matrix is the significant value.\n\nquadrant[localMI[,5]>signif] <- 0\nquadrant\n\n [1] 0 0 0 0 0 0 4 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 2 0 0 0 4 0 0 4 0 0\n[77] 0 2 0 0 0 0 0 4 0 2 0 0\n\n\nCombining all the steps above into one code chunk:\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1 # LL\nquadrant[DV >0 & LM_I<0] <- 2 # LH\nquadrant[DV <0 & LM_I<0] <- 3 # HL\nquadrant[DV >0 & LM_I>0] <- 4 # HH\nquadrant[localMI[,5]>signif] <- 0 # non-sig\n\n\n\n10.7.4 Plotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], #index starts from 1\n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_text('County',\n          size = 0.5)+\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title='LISA map (significant)',\n            legend.width = 0.25,\n            legend.height = 0.25)\n\nLISAmap\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding LISA map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ntmap_arrange(localMI.map, LISAmap,\n             asp=1,\n             ncol=2 )\n\n\n\n\n\n‘Clustering of dissimilar values’ (Local Moran I < 0) is also known as ‘dispersion’ or ‘outlier’ region.\nThe darker green regions shows signs of clustering of similar values while the orange regions shows signs of dispersion (cluster of dissimilar values). The LISA map on the right will be able to give more detailed insights, for e.g. for cluster regions whether is it HH or LL and for the outliers region whether its LH or HL.\n\nThe GDPPC and LISA Map can also be placed side by side .\n\ngdppc <- qtm(hunan, 'GDPPC')\ntmap_arrange(gdppc, LISAmap,\n             asp=1,\n             ncol=2)\n\n\n\n\n\nLISAmap:\nThe dark blue and red regions are clusters of LL and HH respectively.\nThe light blue regions are outliers (LH), where those regions have relatively lower values than their neighbours."
  }
]